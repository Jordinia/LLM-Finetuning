{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1eea4c6f",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10039837",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fishmon/.conda/envs/unsloth_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from jsonschema import validate, ValidationError\n",
    "from datasets import Dataset, load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9056f1cb",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14a3927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = load_dataset(\"json\", data_files=\"./dataset/netpro_chatml_thought.jsonl\")\n",
    "\n",
    "dataset = load_dataset(\"jordinia/netpro-finetune\", split = \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfc5a2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = dataset[\"train\"]  # Access the 'train' split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ed36710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output Type: <class 'datasets.arrow_dataset.Dataset'>\n",
      "Dataset Info:\n",
      "Dataset({\n",
      "    features: ['conversations'],\n",
      "    num_rows: 33262\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nOutput Type:\", type(dataset))\n",
    "print(\"Dataset Info:\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8651d1",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4834df0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 2.5.1 with CUDA 1201 (you have 2.6.0+cu124)\n",
      "    Python  3.11.10 (you have 3.11.11)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Failed to patch Gemma3ForConditionalGeneration.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 3090 Ti. Num GPUs = 1. Max memory: 23.551 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.1.\n",
      "Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.\n",
      "Unsloth 2025.3.19 patched 28 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import torch\n",
    "from unsloth import FastLanguageModel\n",
    "from typing import Dict, Any\n",
    "\n",
    "def load_config(config_path: str) -> Dict[str, Any]:\n",
    "    with open(config_path, 'r') as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "config = load_config('./config/config-0305.yml')\n",
    "\n",
    "# Model and Training Config\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=config.get('model_name', 'unsloth/Llama-3.2-3B-Instruct-bnb-4bit'),\n",
    "    max_seq_length=config.get('max_seq_length', 30000),\n",
    "    dtype=config.get('dtype', None),\n",
    "    load_in_4bit=config.get('load_in_4bit', True)\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=config.get('lora_r', 32),\n",
    "    target_modules=config.get('target_modules', [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]),\n",
    "    lora_alpha=config.get('lora_alpha', 32),\n",
    "    lora_dropout=config.get('lora_dropout', 0),\n",
    "    bias=config.get('bias', 'none'),\n",
    "    use_gradient_checkpointing=config.get('use_gradient_checkpointing', 'unsloth'),\n",
    "    random_state=config.get('random_state', 3407),\n",
    "    use_rslora=config.get('use_rslora', False),\n",
    "    loftq_config=config.get('loftq_config', None),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4eb134c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth.chat_templates import get_chat_template\n",
    "\n",
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template = \"llama-3.1\",\n",
    ")\n",
    "\n",
    "def formatting_prompts_func(examples):\n",
    "    convos = examples[\"conversations\"]\n",
    "    texts = [tokenizer.apply_chat_template(convo, tokenize = False, add_generation_prompt = False) for convo in convos]\n",
    "    return { \"text\" : texts, }\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10d2424f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(formatting_prompts_func, batched = True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a875a0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = dataset.train_test_split(test_size=0.004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3c5151d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['conversations', 'text'],\n",
       "        num_rows: 33128\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['conversations', 'text'],\n",
       "        num_rows: 134\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264b1044",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87c48ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjordinia\u001b[0m (\u001b[33mjordinia-netpro\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @title wandb init\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "434ca268",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_WATCH=all\n",
      "env: WANDB_SILENT=true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/fishmon/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%env WANDB_WATCH=all\n",
    "%env WANDB_SILENT=true\n",
    "wandb.login(relogin=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3b1d11a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/fishmon/AJ/LLM-Finetuning/Malicious-Web/wandb/run-20250503_214255-1h3k5su0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jordinia-netpro/netpro-finetune/runs/1h3k5su0' target=\"_blank\">llama-3.2-3b-instruct-unsloth-sft-2025-05-03</a></strong> to <a href='https://wandb.ai/jordinia-netpro/netpro-finetune' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jordinia-netpro/netpro-finetune' target=\"_blank\">https://wandb.ai/jordinia-netpro/netpro-finetune</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jordinia-netpro/netpro-finetune/runs/1h3k5su0' target=\"_blank\">https://wandb.ai/jordinia-netpro/netpro-finetune/runs/1h3k5su0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to WANDB!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from transformers.utils import logging\n",
    "import wandb\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # Loads from .env file automatically\n",
    "\n",
    "# 2. Verify token loading\n",
    "if not os.getenv(\"WANDB_API_KEY\"):\n",
    "    raise ValueError(\"WANDB_API_KEY not found in .env file\")\n",
    "\n",
    "# 3. Initialize and upload\n",
    "os.environ[\"WANDB_API_KEY\"]=os.getenv(\"WANDB_API_KEY\")\n",
    "\n",
    "logging.set_verbosity_info()\n",
    "project_name = \"netpro-finetune\" \n",
    "entity_name = \"jordinia-netpro\"\n",
    "run_name = \"llama-3.2-3b-instruct-unsloth-sft-2025-05-03\"  # Set your desired run name\n",
    "\n",
    "# Initialize WANDB (FIXED ENTITY/PROJECT)\n",
    "try:\n",
    "    run = wandb.init(\n",
    "        entity=entity_name,\n",
    "        project=project_name,\n",
    "        name=run_name,\n",
    "        # id=\"j4vh49mi\",\n",
    "        # resume=\"allow\" # Uncomment to resume a previous run\n",
    "    )\n",
    "    print(\"Successfully connected to WANDB!\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to initialize WANDB: {str(e)}\")\n",
    "    # Consider exiting if WANDB is critical\n",
    "    # sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "052ed88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "PyTorch: setting up devices\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "Using auto half precision backend\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir                  =config.get('output_dir', 'outputs'),\n",
    "    per_device_train_batch_size =config.get('per_device_train_batch_size', 2),\n",
    "    per_device_eval_batch_size  =config.get('per_device_eval_batch_size', 1),\n",
    "    gradient_accumulation_steps =config.get('gradient_accumulation_steps', 4),\n",
    "    warmup_ratio                =config.get('warmup_ratio', 0.05),\n",
    "    max_steps                   =config.get('max_steps', 4125),\n",
    "    learning_rate               =2e-5,\n",
    "    fp16                        =not is_bfloat16_supported(),\n",
    "    bf16                        =is_bfloat16_supported(),\n",
    "    optim                       =config.get('optim', 'adamw_8bit'),\n",
    "    weight_decay                =config.get('weight_decay', 0.1),\n",
    "    lr_scheduler_type           =config.get('lr_scheduler_type', 'cosine'),\n",
    "    eval_strategy               =config.get('eval_strategy', 'steps'),\n",
    "    eval_steps                  =config.get('eval_steps', 50),\n",
    "    save_strategy               =config.get('save_strategy', 'steps'),\n",
    "    save_steps                  =config.get('save_steps', 100),\n",
    "    save_total_limit            =config.get('save_total_limit', 3),\n",
    "    logging_steps               =config.get('logging_steps', 10),\n",
    "    seed                        =config.get('seed', 3407),\n",
    "    report_to                   =config.get('report_to', 'wandb'),\n",
    "    load_best_model_at_end      =config.get('load_best_model_at_end', True),\n",
    "    metric_for_best_model       =config.get('metric_for_best_model', 'eval_loss'),\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model               =model,\n",
    "    tokenizer           =tokenizer,\n",
    "    train_dataset       =dataset_dict[\"train\"],\n",
    "    eval_dataset        =dataset_dict[\"test\"],\n",
    "    dataset_text_field  =config.get('dataset_text_field', 'text'),\n",
    "    max_seq_length      =config.get('max_seq_length', 30000),\n",
    "    data_collator       =DataCollatorForSeq2Seq(\n",
    "        tokenizer               =tokenizer,\n",
    "        padding                 =config.get('data_collator', {}).get('padding', True),\n",
    "        pad_to_multiple_of      =config.get('data_collator', {}).get('pad_to_multiple_of', 8),\n",
    "        max_length              =config.get('max_seq_length', 30000),\n",
    "    ),\n",
    "    dataset_num_proc    =config.get('dataset_num_proc', 2),\n",
    "    packing             =config.get('packing', False),\n",
    "    args                =args,\n",
    ")\n",
    "\n",
    "# # Calculate training length (33k samples)\n",
    "# total_samples = 33000  # Your balanced dataset size\n",
    "# batch_size = 2 * 4  # batch_size * gradient_accum\n",
    "# steps_per_epoch = total_samples // batch_size  # ~4125 steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798cc344",
   "metadata": {},
   "source": [
    "### Train on Completions Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07252b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_on_responses_only_custom(trainer):\n",
    "#     \"\"\"\n",
    "#     Custom version for website classification that:\n",
    "#     1. Preserves system prompt context\n",
    "#     2. Only trains on assistant responses (JSON + reasoning)\n",
    "#     3. Handles length consistency for batching\n",
    "#     \"\"\"\n",
    "#     tokenizer = trainer.tokenizer\n",
    "    \n",
    "#     # Manually define token sequences for your template\n",
    "#     SYSTEM_TOKENS = tokenizer.encode(\n",
    "#         \"<|start_header_id|>system<|end_header_id|>\\n\\n\", \n",
    "#         add_special_tokens=False\n",
    "#     )\n",
    "#     USER_TOKENS = tokenizer.encode(\n",
    "#         \"<|start_header_id|>user<|end_header_id|>\\n\\n\", \n",
    "#         add_special_tokens=False\n",
    "#     )\n",
    "#     ASSISTANT_TOKENS = tokenizer.encode(\n",
    "#         \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\", \n",
    "#         add_special_tokens=False\n",
    "#     )\n",
    "\n",
    "#     def custom_masking(examples):\n",
    "#         input_ids = examples[\"input_ids\"]\n",
    "        \n",
    "#         # Create labels if they don't exist\n",
    "#         labels = examples.get(\"labels\", [ids.copy() for ids in input_ids])\n",
    "#         new_labels = []\n",
    "        \n",
    "#         for seq_id, seq_labels in zip(input_ids, labels):\n",
    "#             n = len(seq_id)\n",
    "#             mask = [-100] * n\n",
    "#             i = 0\n",
    "            \n",
    "#             while i < n:\n",
    "#                 # Check for system prompt\n",
    "#                 if seq_id[i:i+len(SYSTEM_TOKENS)] == SYSTEM_TOKENS:\n",
    "#                     i += len(SYSTEM_TOKENS)\n",
    "#                     continue\n",
    "                    \n",
    "#                 # Check for user prompt\n",
    "#                 if seq_id[i:i+len(USER_TOKENS)] == USER_TOKENS:\n",
    "#                     i += len(USER_TOKENS)\n",
    "#                     continue\n",
    "                    \n",
    "#                 # Check for assistant prompt\n",
    "#                 if seq_id[i:i+len(ASSISTANT_TOKENS)] == ASSISTANT_TOKENS:\n",
    "#                     start = i\n",
    "#                     i += len(ASSISTANT_TOKENS)\n",
    "                    \n",
    "#                     # Find end of assistant response\n",
    "#                     while i < n:\n",
    "#                         if seq_id[i] == tokenizer.eos_token_id:\n",
    "#                             end = i\n",
    "#                             break\n",
    "#                         i += 1\n",
    "#                     else:\n",
    "#                         end = n\n",
    "                    \n",
    "#                     # Unmask assistant response\n",
    "#                     mask[start:end] = seq_labels[start:end]\n",
    "#                     break\n",
    "                    \n",
    "#                 i += 1\n",
    "            \n",
    "#             # Enforce length matching (critical fix)\n",
    "#             if len(mask) != len(seq_id):\n",
    "#                 mask = mask[:len(seq_id)] + [-100] * (len(seq_id) - len(mask))\n",
    "            \n",
    "#             new_labels.append(mask)\n",
    "        \n",
    "#         return {\"labels\": new_labels}\n",
    "\n",
    "#     # Apply to datasets with length verification\n",
    "#     def apply_masking(dataset):\n",
    "#         dataset = dataset.map(\n",
    "#             custom_masking,\n",
    "#             batched=True,\n",
    "#             batch_size=1000,\n",
    "#             num_proc=4,\n",
    "#         )\n",
    "#         # Verify lengths\n",
    "#         for i in range(min(3, len(dataset))):\n",
    "#             assert len(dataset[i][\"input_ids\"]) == len(dataset[i][\"labels\"]), \\\n",
    "#                 f\"Length mismatch in sample {i}\"\n",
    "#         return dataset\n",
    "    \n",
    "#     trainer.train_dataset = apply_masking(trainer.train_dataset)\n",
    "    \n",
    "#     if trainer.eval_dataset is not None:\n",
    "#         trainer.eval_dataset = apply_masking(trainer.eval_dataset)\n",
    "        \n",
    "#     return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9499b5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = train_on_responses_only_custom(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96e2c0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Final verification (optional)\n",
    "# print(\"\\n=== Final Pre-Train Check ===\")\n",
    "# sample = trainer.train_dataset[0]\n",
    "# print(\"First sample labels preview:\")\n",
    "# print(\"Input IDs length:\", len(sample[\"input_ids\"])) \n",
    "# print(\"Labels length:\", len(sample[\"labels\"]))\n",
    "# print(\"Last 10 labels:\", sample[\"labels\"][-10:])  # Should show unmasked assistant tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6841e8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get a sample from the training set\n",
    "# sample_index = 5  # Try different indices\n",
    "# sample = trainer.train_dataset[sample_index]\n",
    "\n",
    "# # Decode the full input context\n",
    "# print(\"==== Full Input Context ====\")\n",
    "# print(tokenizer.decode(sample[\"input_ids\"]))\n",
    "# print(\"\\n\")\n",
    "\n",
    "# # Decode the labels with masking visualization\n",
    "# print(\"==== Training Targets (Masked) ====\")\n",
    "# masked_labels = []\n",
    "# for token_id, label_id in zip(sample[\"input_ids\"], sample[\"labels\"]):\n",
    "#     if label_id == -100:\n",
    "#         # Show masked tokens as blank spaces\n",
    "#         masked_labels.append(\" \")\n",
    "#     else:\n",
    "#         # Show actual token\n",
    "#         masked_labels.append(tokenizer.decode([token_id]))\n",
    "\n",
    "# print(\"\".join(masked_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "136a307b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = trainer.train_dataset.select(range(2)).with_format(\"torch\")[0]\n",
    "# print(batch[\"input_ids\"])\n",
    "# print(batch[\"labels\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c221f500",
   "metadata": {},
   "source": [
    "### Memory Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7c95376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['conversations', 'text', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 33128\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b14b138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conversations': [{'content': 'You are an Expert Website Classifier tasked with categorizing websites (using provided Domain & Content) into distinct categories: **0 - Benign**, **1 - Gambling**, **2 - Pornography**, or **3 - Harmful**. Output strict JSON including classification, reason, and a point-based confidence score (0-100). This aids a sophisticated website prediction system for digital safety.\\n\\n### **Categories & Definitions:**\\n\\n-   **0 - Benign:** General info, news, entertainment, services, e-commerce, educational sites, blogs, informational pages, and general entertainment sites. No gambling/porn themes.\\n    -   **Includes:** Educational discussion of sensitive topics (drugs, gambling, adult, illegal), suggestive content (dating, lingerie) *without* explicit material, drugs for educational or news purposes (e.g., addiction recovery, medical cannabis research).\\n\\n-   **1 - Gambling:** Promotes/facilitates betting, casino, poker, lottery, wagering. Includes online betting platforms, casinos, poker sites, lottery sites, and any website that encourages or provides means for users to wager money on games of chance or skill.\\n    -   **Keywords:** betting, casino, poker, odds, jackpot, slots, roulette, judi, slot gacor, togel, similar gambling-related terminology within their domain name or content.\\n    \\n-   **2 - Pornography:** These are websites that contain explicit sexual content intended to cause arousal. Explicit sexual content (images, videos, text) for arousal. Immoral content (bestiality, child exploitation). or links to such materials. \\n    -   **Keywords:** porn, bokep, sex, xxx, adult, nude, erotic, explicit video/photo.\\n\\n- **3 - Harmful**: Websites that does not fall to Benign, Gambling, and Pornography category. These websites engage in or promote activities harmful to users or violating laws/regulations, including:\\n    - Malware Distribution: Hosting/downloading computer viruses, worms, ransomware, spyware, etc.\\n    - Cybercrime: Phishing kits, hacking tools, stolen data markets, carding forums.\\n    - Extremism & Terrorism: Content inciting violence, extremist ideologies, or terrorist recruitment.\\n    - Violations of Indonesian Law:\\n        - Insults, defamation, blackmail, or threats.\\n        - Hoaxes/misleading news, hate speech, or incitement of violence.\\n    - Copyright Infringement/Piracy: Illegal software/cracks, torrents, pirated media.\\n    - Drugs/Narcotics: Sale/promotion of illegal drugs (e.g., cocaine, heroin) or unregulated pharmaceuticals.\\n    - Weapons: Sale of illegal firearms, explosives, or weapons.\\n    - Other Illegal Activities: Counterfeit goods, money laundering, human trafficking.\\n    - **Examples:**  \\n        - Illegal: `darknet-drugs.com` (drug sales), `pirated-movies.id` (piracy).  \\n        - Harmful: `extremist-forum.net` (terrorism recruitment), `hackers-tools.org` (phishing kits).  \\n        - Scam/phishng: `hadiah-telkomsel7.blogspot.com` (non-genuine website).\\n    - **Keywords**:\\nmalware, ransomware, phishing, hack, terrorism, jual narkoba, senjata ilegal, konten SARA, berita bohong, ancaman, pembajakan, cracked software, carding, darknet.\\n    - **Exceptions:** \\n        - Licensed/unlicensed gambling â†’ **1 - Gambling**; scams â†’ **3 - Harmful**.\\n\\n\\n### **Input Data Context:**\\n\\nYou will be provided with data entries, each consisting of two primary fields:\\n\\n*   **Domain:** The domain name or URL of the website (e.g., `example.com`, `gamble-site.net`). This can provide hints about the website\\'s purpose.\\n*   **Content:**  The textual content scraped from the website. This content offers detailed information about the website\\'s topics, services, and themes.\\n\\n### **Labeling Instructions:**\\n\\nAnalyze both the **Domain** and the **Content** provided. Use keywords and contextual clues from both to determine the most appropriate category for the website.  Consider the primary purpose and content focus of the website when classifying.\\n\\n### **Confidence Assessment Guidelines: Point-Based System (Total Possible Points: 100)**\\n\\nTo determine the **confidence** level (0-100) for your classification, evaluate the following factors and sum up the points.  The total points will directly correspond to the confidence percentage (e.g., 95 points = 95% confidence).\\n\\n#### **I. Keyword Strength and Relevance (Maximum 40 Points)**\\n*   **(40 Points):  Exceptional Keyword Strength: Explicit and Overwhelming Keywords in BOTH Domain and Content:** Presence of extremely explicit and overwhelmingly strong keywords that are *unquestionably* indicative of a specific category in *both* the domain name AND the website content. These keywords leave absolutely no doubt about the website\\'s nature. (e.g., Domain: `casino-royal-betting.com`, Content:  \"Gamble now and win HUGE jackpots on slots, poker, roulette! Real money betting!\").  This represents the absolute strongest keyword signal possible.\\n*   **(35 Points): Clear and Strong Keywords in BOTH Domain and Content:**  Presence of highly explicit keywords strongly indicative of a specific category in both the domain name AND the website content. (e.g., Domain: `bet.com`, Content:  \"Bet on sports and casino games!\").\\n*   **(25 Points): Strong Keywords in EITHER Domain OR Content:** Presence of highly explicit keywords strongly indicative of a specific category in EITHER the domain name OR the website content, but not both.\\n*   **(15 Points): Some Relevant Keywords:** Presence of keywords related to a category, but they are less explicit, less frequent, or require more contextual interpretation in either domain or content.\\n*   **(0 Points): Weak or Generic Keywords:** Lack of clear category-specific keywords in both domain and content. Keywords are generic and do not strongly suggest any specific category.\\n\\n#### **II. Domain and Content Alignment (Maximum 30 Points)**\\n\\n*   **(30 Points): Strong Domain and Content Alignment:** Domain name strongly and unambiguously suggests a category, and the website content consistently and explicitly reinforces that category.  They tell the same clear story.\\n*   **(15 Points): Partial Domain and Content Alignment:** Domain name and content generally point towards the same category, but the alignment might be less direct, slightly ambiguous, or require some interpretation to connect them.\\n*   **(0 Points): Domain-Content Mismatch or No Alignment:** Domain name suggests one thing, but the content is unclear, suggests something different, or there\\'s no clear connection between the domain and the content\\'s apparent purpose.\\n\\n#### **III. Content Clarity and Unambiguity (Maximum 20 Points)**\\n\\n*   **(20 Points): Unambiguous and Explicit Content:** The website content is very clear, direct, and leaves virtually no room for interpretation. It unambiguously falls into one of the defined categories.\\n*   **(10 Points): Content Requires Some Interpretation:** The content generally points to a category, but requires some interpretation to confidently assign it.  There might be subtle hints, implied meanings, or a need to infer the primary purpose.\\n*   **(0 Points): Ambiguous or Conflicting Content:** The website content is vague, contradictory, or could be reasonably interpreted in multiple ways, making it difficult to confidently assign a category.\\n\\n#### **IV. Category Indicator Strength (Maximum 10 Points)**\\n\\n*   **(10 Points): Multiple Strong Category Indicators:** Presence of numerous strong and clear indicators for a specific category throughout the domain and content (e.g., for Pornography: explicit keywords, descriptions of sexual acts, calls to action to view adult content, age verification prompts).\\n*   **(5 Points): Some Category Indicators Present:** Presence of a few indicators for a category, but they are not overwhelmingly strong or numerous.\\n*   **(0 Points): Lack of Category Indicators:** Few or no clear indicators for any of the defined categories are present in the domain and content.\\n\\n#### **Calculation:**\\n\\n1.  For each of the four sections (I-IV), assess the website and select the point value that best describes the presence of the described factors.\\n2.  Sum up the points from all four sections.\\n3.  The total sum represents the confidence level in percentage (%).\\n\\n#### **Confidence Level Ranges (for reference - already implicitly defined by points):**\\n\\n*   **High Confidence (80-100 Points):**  Strong evidence across multiple factors pointing clearly to a category.\\n*   **Medium Confidence (50-79 Points):** Moderate evidence, some ambiguity or less directness in indicators.\\n*   **Low Confidence (0-49 Points):** Weak or conflicting evidence, high uncertainty about the correct category.\\n\\n#### **Example:**\\n\\nLet\\'s say you are classifying `lucky-slots-online.com` with content about slot games and bonuses.\\n\\n*   **I. Keyword Strength:** Strong keywords in both Domain and Content (e.g., \"slots,\" \"online,\" \"win,\" \"bonuses\") - **25 Points**\\n*   **II. Domain-Content Alignment:** Domain and content strongly align with Gambling - **30 Points**\\n*   **III. Content Clarity:** Content is very clear about gambling activities - **20 Points**\\n*   **IV. Category Indicators:** Multiple indicators of gambling (games, bonuses, calls to action) - **10 Points**\\n\\n**Total Points: 25 + 30 + 20 + 10 = 85 Points.  Confidence: 85%**\\n\\n#### **Using this Point System:**\\n\\nWhen generating the \"reason\" for your classification, you can now also briefly mention the points you assigned for each section to justify the final confidence score. For example:\\n\\n```json\\n{\\n  \"answer\": 1,\\n  \"classification\": \"Gambling\",\\n  \"reason\": \"Strong keywords in domain and content (25 pts), strong domain-content alignment (30 pts), clear gambling content (20 pts), multiple category indicators (10 pts). Total 85 points.\",\\n  \"confidence\": 85\\n}\\n```\\n\\n### **Output Requirements: STRICTLY ADHERE TO JSON FORMAT**\\n\\nFor each website, you **MUST** provide your classification in the following **JSON format ONLY**.  **No other format is acceptable.**\\n\\n```json\\n{\\n  \"answer\": (integer: 0, 1, 2, or 3),\\n  \"classification\": (string: \"Benign\", \"Gambling\", \"Pornography\", or \"Harmful\"),\\n  \"reason\": (string: \"Brief explanation of the classification using keywords and hints from the domain and content.\"),\\n  \"confidence\": (integer: 0 to 100, \"Level of confidence in the classification\")\\n}\\n```\\n\\n**Example Input and Expected Output:**\\n\\n**1st Sample**\\n\\n**Input Data:**\\n\\n```\\nDomain: news-today.info\\nContent: Welcome to News Today! Get the latest breaking news, top stories, and in-depth analysis from around the world. Covering politics, business, technology, sports, and culture. Stay informed with News Today - your source for reliable journalism.\\n```\\n\\n**Expected Output:**\\n\\n```json\\n{\\n  \"answer\": 0,\\n  \"classification\": \"Benign\",\\n  \"reason\": \"Domain \\'news-today.info\\' and content mention \\'breaking news,\\' \\'top stories,\\' \\'analysis,\\' \\'reliable journalism,\\' indicating a general information/news website. Strong keywords in domain and content (35 pts), strong domain-content alignment (30 pts), unambiguous content (20 pts), some category indicators (5 pts). Total 90 points.\",\\n  \"confidence\": 90\\n}\\n```\\n\\n**2nd Sample:**\\n\\n**Input Data:**\\n\\n```\\nDomain: lucky-slots-online.com\\nContent:  Spin to win big at Lucky Slots Online! Play hundreds of exciting slot games, claim your bonuses, and join the fun.  Licensed and regulated for your safety. 24/7 customer support available. Join now and get 100 free spins!\\n```\\n\\n**Expected Output:**\\n\\n```json\\n{\\n  \"answer\": 1,\\n  \"classification\": \"Gambling\",\\n  \"reason\": \"Domain \\'lucky-slots-online.com\\' and content include keywords like \\'slots,\\' \\'win,\\' \\'casino,\\' \\'bonuses,\\' \\'free spins,\\' indicating a gambling website.\",\\n  \"confidence\": 100\\n}\\n```\\n\\n**3rd Sample**\\n\\n**Input Data:**\\n\\n```\\nDomain: adult-pleasures.net\\nContent:  Experience the hottest adult entertainment online. Unlimited access to exclusive videos and photos. 18+ only. Join our community of pleasure seekers today!\\n```\\n\\n**Expected Output:**\\n\\n```json\\n{\\n  \"answer\": 2,\\n  \"classification\": \"Pornography\",\\n  \"reason\": \"Domain \\'adult-pleasures.net\\' and content include explicit terms like \\'adult entertainment,\\' \\'exclusive videos,\\' \\'photos,\\' \\'18+ only,\\' and \\'pleasure seekers,\\' indicating a pornography website. Strong keywords in both domain and content (25 pts), strong domain-content alignment (30 pts), unambiguous content (20 pts), multiple category indicators (10 pts). Total 85 points.\",\\n  \"confidence\": 85\\n}\\n```\\n**4th Sample**\\n\\n**Input Data:**\\n\\n```\\nDomain: project420.com\\nContent:  Welcome to Project420.com an ongoing community marijuana, hemp search engine and your gateway to 420 products, services and information from all over the world. Marijuana seeds, super bongs, high tech growing marijuana books, contests, communities, cool people and tons of 420 fun.  Potent marijuana websites are added frequently.  Let\\'s help each other grow.  Use the table of contents located to the left and begin your search of 420 world wide websites.\\n```\\n\\n**Expected Output:**\\n\\n```json\\n{\\n  \"answer\": 3,\\n  \"classification\": \"Harmful\",\\n  \"reason\": \"Domain \\'project420.com\\' and content include keywords like \\'marijuana seeds,\\' \\'growing marijuana,\\' and \\'420 products,\\' indicating promotion of illegal drugs under Indonesian law (UU ITE). Strong keywords in content (25 pts), Partial Domain and Content Alignment (15 pts), clear harmful intent (20 pts), multiple indicators (10 pts). Total 70 points.\",\\n  \"confidence\": 70\\n}\\n```\\n**Execution:**\\nProcess the provided website data (input fields: `Domain`, `Content`). Apply the classification categories, definitions, and confidence point system accurately. Generate the mandatory JSON output for each entry. Begin classification now.',\n",
       "   'role': 'system'},\n",
       "  {'content': 'Classify the given URL as 0 (benign), 1 (gambling), 2 (pornography), or 3 (harmful). Output MUST be JSON.\\n\\nDomain: adevotedslave.blogspot.com, Content: \"Delicious Debauchery If You arenâ€™t over the age 18 (21 in some areas) then please leave. If You are offended by sex, BDSM, phone sex or brutal honesty then this isn\\'t the place for You. FRIDAY, JUNE 08, 2007 Why Iâ€™ll never be a full lesbianâ€¦ You know, it doesnâ€™t seem to matter what I am using or what position I am in. Iâ€™ve tried it with dildos, vibes, my gear shift knob, my fingers, and miscellaneous household objects, with just about anything and every thing I can think of. Iâ€™ve done it on my hands and knees on my back, with one leg up. Iâ€™ve tried putting the base on the floor and bouncing up and down. Iâ€™ve put it up against a wall and pushed against it. It doesnâ€™t matter. Nothing that I do makes it so that I can fuck myself hard enough to make it feel just right. Nothing can take me to that place where I am balancing between the pleasure of being fucked and the pain of having a cock battering my insides. Of course, when Iâ€™m trying to simulate hard fucking it still feels good, but itâ€™s that kind of feeling you get when you are almost there, but not quite. You know where you want to go but you just canâ€™t get there. Itâ€™s frustrating as hell. Besides, I have never actually had a toy, or object Iâ€™ve converted into a toy, thatâ€™s felt like a real cock anyway. They all just feel like random objects that fall short of the glory that is a real, hard, throbbing, piece of flesh designed for fucking. Of course, if thereâ€™s some woman out there whoâ€™s willing to try to convert me into a full fledged lesbian anyway, Iâ€™m more than willing to submit to that kind of training. Who knows? A woman with a strap on may be able to fuck me just like I like. Of course, Iâ€™d not refuse returning the favor. It could be a mutually beneficial experiment. POSTED BY DEIDRE AT 11:13 AM 2 COMMENTS SATURDAY, APRIL 28, 2007 Bruised and Battered For some reason I think that the depth of my pussy fluctuates. Sometimes when Masterâ€™s cock slides inside of me it is the perfect fit. The head hits in just the... en melted apart. A puff of smoke flew up, and there was another familiar sensation... the smell of burned meat. Again the heat, with a dirty orange light where the flame burned away the bits of tissue stuck to the wire. Again the application, the shudder, the pop, the hiss, the smoke. Around the stencil he went, carefully watching the brand, lining up the strikes. As the skin opens along the brand\\'s outline, it shifts. About halfway around, he started almost freehanding, using the stencil as a reminder of what he wanted, not as a guide. Then with the outline complete, and even, he used its angles as a reference for the final strikes down the middle. There were ten strikes in all. Ten times the iron glowed, ten times it lowered to her helpless flesh. Ten times she moaned as her love for me was burned into her very body. As I continued my research I rediscovered Fakirâ€™s site and the process of using an electro-cautery pencil instead of using the striking method with heated ribbons of steel. I showed a few examples to Master, including a photo of hisdevotionâ€™s back. He asked how one goes about getting an electro-cautery pencil. Until that moment it never even occurred to me that a person outside of the medical profession could just go and buy one. Well, for less than a hundred bucks one can buy a battery operated one with various different tips. Something wonderful happened as I scrolled through all of the options for this tool. I began reading in the descriptions that they get up to 2200 degrees Fahrenheit. Instead of the fear I expected to feel at such a number I felt the nervous flutters of excitement. If Master decides to go this direction, and have His mark of ownership burned into my skin in this fashion, I will have 2200 degrees focused on my skin, burning me, marking me bit by bit. This makes me incredibly aroused. Perhaps I have the makings of a pain slut afterall. POSTED BY DEIDRE AT 1:43 PM 0 COMMENTS TUESDAY, MARCH 13, 2007 masks Iâ€™ve said before that my relationship with Master and the trust and honesty that is the foundation of that relationship has made me more fully myself than I ever have been before. I am more aware of the different aspects of myself and I am able to lie them all out on the table to be poked at and prodded by any stranger who happens by. On the other hand there are those for whom I must wear certain masks. My relationship with Master might have inspired an intense honesty with myself and with Him, as well as with those who can accept us this way and those whose judgement doesnâ€™t matter, but itâ€™s also forced me to be more dishonest than ever to those around me, my neighbors, friends and family. I have been asked by potential sisters, by friends and by callers about how the world sees me. What does Master let the neighbors see? His friends? My friends? My family? His family? Itâ€™s all kind of complicated. The neighbors/His friends: * My neighbors see a 28 year old girl who is living with a 53 year old man. They see the 2 of us happily interacting with each other. He is very active in our neighborhood community. I am not. I occasionally wave to the neighbors or have a conversation with them and most of the time they say something to the effect of, \"Itâ€™s been a while. How have you been?\" Most of them are nice people, but I have little desire to interact with them. They know that I am a phone sex operator and most of them are intrigued. They do not know that I am a slave but there are probably quite a few who have observed that I donâ€™t make any decisions of importance. My friends: * My friends all know just about everything there is to know. Friends that I consider to be mine (as opposed to those that I know because of Master) are basically those from the internet. This includes a few people from collarme and other personals sites but the vast majority is made up of people from LiveJournal. LiveJournal is where all of my meaningful social interaction takes place, as sad as that may seem. There just arenâ€™t a whole lot of people like me nearby and being friends with a girl whoâ€™s first priority is never friendships can be trying. His family: * Masterâ€™s brother, K. He is aware of the basics of the dynamics between Master and myself however itâ€™s never discussed with him and itâ€™s never thrown in his face. We donâ€™t play or fuck in front of K. Iâ€™ve never been loaned to K. Master and I have discussed it and if K is anything heâ€™s probably more submissive than dominant. K knows that I am a phone sex operator. I think he may have heard me on occasion when I am taking calls. * The rest of Masterâ€™s family. He has one of those families that has reunions every year. The patriarch of the family is in his 90s and still kicking. I havenâ€™t met everyone yet, but Iâ€™ve met the ones that are either closest or that Master likes the most. They have opened their arms and accepted me, making me an honorary â€“insert Masterâ€™s family name here- One of them told me over thanksgiving that she has never seen Master as happy as he is now and she thinks that I am to thank for that. What higher compliment can someone pay me than that? My Family: * My sister, E, and I used to be very close. Weâ€™re not anymore though. When I went to her house last summer I had just come from my fathers and wasnâ€™t wearing my collar. The first night I was getting ready to go out with her and my mother and put it back on. Her reaction was that my necklace didnâ€™t match my outfit and I should take the jewelry off. I refused explaining that Master (I used his first name) gave it to me and I hadnâ€™t really had it off since except for when I visited dad. I think she started to get the idea at that point. She knew a little before then, but I think the image of me collared finished off any of the blank parts in her imagination of how I was living my life. I donâ€™t think she approves. We havenâ€™t spoken since then. Iâ€™m not sure how much my lifestyle has to do with that though. * My mother knows the pieces and details that I think sh...  get enough. Sheâ€™s become my newest addiction. I lick the juice of her squirt from my arm and slide my fingers from her into my mouth. I love that taste. Outside the sun is beginning to rise. Weâ€™ve been lost in each other for the entire night. The magic begins to dissipate. We get dressed once again shy and nervous. The blush on my face doesnâ€™t stop me from telling her how much I enjoyed the night. It turns out that she did too and that we both want to do it again. Soon. POSTED BY DEIDRE AT 1:59 PM 0 COMMENTS Older Posts Home Subscribe to: Posts (Atom) ABOUT DEIDRE DEIDRE STRADDLING THE LINE BETWEEN FANTASY AND REALITY deidre is a 28 yo lifestyle slave, phone sex operator and fetish model. she is happily owned. VIEW MY COMPLETE PROFILE LINKS 101 Things about deidre NITEFLIRT delicious debauchery Join for Free What is NiteFlirt? MP3 RECORDINGS The Holy Fuck **fetish sample Gender Blender **hypnosis sample How to Get Out of a Ticket **fetish sample Gym Discipline **fetish sample French Maid **fetish sample Lesbian Strap-on BDSM **fetish sample Lesbian Tickle Bondage **fetish sample Isabella\\'s Sex Slave **hypnosis sample Gagged By Goddess **fetish sample Boarding School Humiliation **fetish sample RECORDINGS (BY THE MINUTE) rates and descriptions deidre\\'s daily prayer deidre gets face fucked equipment sampler deidre\\'s discipline barking cough tickle torture psalm 23 (deidre style) a steamy shower & my fav toy PHOTO SETS rates and descriptions teddy bears & coloring books deidre\\'s puppy training photo sampler bondage the golden set deidre\\'s naughty picnic deidre in distress foot bondage PODCASTS Session 2 Interview with Miss Isabella Session 1 WISHFUL THINKING amazon wishlist deidre\\'s corset fund LABELS questions (13) NiteFlirt (12) mp3 (11) calls (6) gifts (5) music (5) pics (2) podcast (2) meme (1) quotes (1) BLOG ARCHIVE â–¼ 2007 (41) â–¼ JUNE (1) â–¼ JUN 08 (1) WHY Iâ€™LL NEVER BE A FULL LESBIANâ€¦ â–º APRIL (2) â–º MARCH (6) â–º FEBRUARY (11) â–º JANUARY (21) â–º 2006 (117) â–º 1978 (2)\"',\n",
       "   'role': 'user'},\n",
       "  {'content': '<think>\\nOkay, I need to classify this website into one of the four categories: Benign, Gambling, Pornography, or Harmful. Let\\'s start by looking at the domain and content provided.  The domain is adevotedslave.blogspot. com. The word \"slavery\" in the domain could be a red flag because it might relate to harmful activities like human trafficking. But I should also consider if it\\'s used in a different context, such as BDSM or kink communities which are more about consensual adult content.  Looking at the content, there are several posts discussing BDSM practices, phone sex, and explicit sexual scenarios. For example, one post talks about trying various objects for self-pleasure and another describes a session involving masks and domination. There\\'s also mention of being a \"lifestyle slave\" and a \"phone sex operator,\" which suggests the site is focused on adult content.  The content includes terms like \"BDSM,\" \"fetish,\" \"bondage,\" and explicit descriptions of sexual acts. These keywords are strong indicators of Pornography because they relate to adult themes and explicit material intended for arousal.  However, I should check if it falls under Harmful instead. The website doesn\\'t seem to promote illegal activities like drug sales or cybercrime. It\\'s more about consensual adult content, which would typically fall under Pornography rather than Harmful unless there are elements of non-consent or exploitation, which aren\\'t clearly present here.  The domain and content align well with Pornography because the focus is on explicit sexual content and fetishes. There are no strong indicators pointing towards Gambling or Benign categories. The content is unambiguous in its adult themes, so it doesn\\'t seem to be a case of harmful activities outside the scope of Pornography.  In terms of confidence assessment: - Keyword Strength: Strong keywords like \"fetish,\" \"bondage,\" and explicit sexual descriptions are present both in the domain and content. - Domain-Content Alignment: The domain suggests a BDSM or slavery theme, which is reinforced by the content discussing explicit adult scenarios. - Content Clarity: The content is very clear about its focus on adult entertainment and fetishes without ambiguity. - Category Indicators: Multiple indicators such as explicit sexual descriptions, use of terms like \"phone sex operator,\" and detailed accounts of BDSM practices.  Based on these factors, I\\'m confident that this website falls under the Pornography category with a high confidence score.\\n</think>\\n```json\\n{\\n  \"answer\": 2,\\n  \"classification\": \"Pornography\",\\n  \"reason\": \"The domain \\'adevotedslave. blogspot.com\\' and content include explicit terms like \\'BDSM,\\' \\'fetish,\\' \\'bondage,\\' and detailed descriptions of sexual acts, indicating a focus on adult entertainment. Strong keywords in both domain and content (25 pts), strong domain-content alignment (30 pts), unambiguous content (20 pts), multiple category indicators (10 pts). Total 85 points.\",\\n  \"confidence\": 85\\n}\\n```',\n",
       "   'role': 'assistant'}],\n",
       " 'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\nYou are an Expert Website Classifier tasked with categorizing websites (using provided Domain & Content) into distinct categories: **0 - Benign**, **1 - Gambling**, **2 - Pornography**, or **3 - Harmful**. Output strict JSON including classification, reason, and a point-based confidence score (0-100). This aids a sophisticated website prediction system for digital safety.\\n\\n### **Categories & Definitions:**\\n\\n-   **0 - Benign:** General info, news, entertainment, services, e-commerce, educational sites, blogs, informational pages, and general entertainment sites. No gambling/porn themes.\\n    -   **Includes:** Educational discussion of sensitive topics (drugs, gambling, adult, illegal), suggestive content (dating, lingerie) *without* explicit material, drugs for educational or news purposes (e.g., addiction recovery, medical cannabis research).\\n\\n-   **1 - Gambling:** Promotes/facilitates betting, casino, poker, lottery, wagering. Includes online betting platforms, casinos, poker sites, lottery sites, and any website that encourages or provides means for users to wager money on games of chance or skill.\\n    -   **Keywords:** betting, casino, poker, odds, jackpot, slots, roulette, judi, slot gacor, togel, similar gambling-related terminology within their domain name or content.\\n    \\n-   **2 - Pornography:** These are websites that contain explicit sexual content intended to cause arousal. Explicit sexual content (images, videos, text) for arousal. Immoral content (bestiality, child exploitation). or links to such materials. \\n    -   **Keywords:** porn, bokep, sex, xxx, adult, nude, erotic, explicit video/photo.\\n\\n- **3 - Harmful**: Websites that does not fall to Benign, Gambling, and Pornography category. These websites engage in or promote activities harmful to users or violating laws/regulations, including:\\n    - Malware Distribution: Hosting/downloading computer viruses, worms, ransomware, spyware, etc.\\n    - Cybercrime: Phishing kits, hacking tools, stolen data markets, carding forums.\\n    - Extremism & Terrorism: Content inciting violence, extremist ideologies, or terrorist recruitment.\\n    - Violations of Indonesian Law:\\n        - Insults, defamation, blackmail, or threats.\\n        - Hoaxes/misleading news, hate speech, or incitement of violence.\\n    - Copyright Infringement/Piracy: Illegal software/cracks, torrents, pirated media.\\n    - Drugs/Narcotics: Sale/promotion of illegal drugs (e.g., cocaine, heroin) or unregulated pharmaceuticals.\\n    - Weapons: Sale of illegal firearms, explosives, or weapons.\\n    - Other Illegal Activities: Counterfeit goods, money laundering, human trafficking.\\n    - **Examples:**  \\n        - Illegal: `darknet-drugs.com` (drug sales), `pirated-movies.id` (piracy).  \\n        - Harmful: `extremist-forum.net` (terrorism recruitment), `hackers-tools.org` (phishing kits).  \\n        - Scam/phishng: `hadiah-telkomsel7.blogspot.com` (non-genuine website).\\n    - **Keywords**:\\nmalware, ransomware, phishing, hack, terrorism, jual narkoba, senjata ilegal, konten SARA, berita bohong, ancaman, pembajakan, cracked software, carding, darknet.\\n    - **Exceptions:** \\n        - Licensed/unlicensed gambling â†’ **1 - Gambling**; scams â†’ **3 - Harmful**.\\n\\n\\n### **Input Data Context:**\\n\\nYou will be provided with data entries, each consisting of two primary fields:\\n\\n*   **Domain:** The domain name or URL of the website (e.g., `example.com`, `gamble-site.net`). This can provide hints about the website\\'s purpose.\\n*   **Content:**  The textual content scraped from the website. This content offers detailed information about the website\\'s topics, services, and themes.\\n\\n### **Labeling Instructions:**\\n\\nAnalyze both the **Domain** and the **Content** provided. Use keywords and contextual clues from both to determine the most appropriate category for the website.  Consider the primary purpose and content focus of the website when classifying.\\n\\n### **Confidence Assessment Guidelines: Point-Based System (Total Possible Points: 100)**\\n\\nTo determine the **confidence** level (0-100) for your classification, evaluate the following factors and sum up the points.  The total points will directly correspond to the confidence percentage (e.g., 95 points = 95% confidence).\\n\\n#### **I. Keyword Strength and Relevance (Maximum 40 Points)**\\n*   **(40 Points):  Exceptional Keyword Strength: Explicit and Overwhelming Keywords in BOTH Domain and Content:** Presence of extremely explicit and overwhelmingly strong keywords that are *unquestionably* indicative of a specific category in *both* the domain name AND the website content. These keywords leave absolutely no doubt about the website\\'s nature. (e.g., Domain: `casino-royal-betting.com`, Content:  \"Gamble now and win HUGE jackpots on slots, poker, roulette! Real money betting!\").  This represents the absolute strongest keyword signal possible.\\n*   **(35 Points): Clear and Strong Keywords in BOTH Domain and Content:**  Presence of highly explicit keywords strongly indicative of a specific category in both the domain name AND the website content. (e.g., Domain: `bet.com`, Content:  \"Bet on sports and casino games!\").\\n*   **(25 Points): Strong Keywords in EITHER Domain OR Content:** Presence of highly explicit keywords strongly indicative of a specific category in EITHER the domain name OR the website content, but not both.\\n*   **(15 Points): Some Relevant Keywords:** Presence of keywords related to a category, but they are less explicit, less frequent, or require more contextual interpretation in either domain or content.\\n*   **(0 Points): Weak or Generic Keywords:** Lack of clear category-specific keywords in both domain and content. Keywords are generic and do not strongly suggest any specific category.\\n\\n#### **II. Domain and Content Alignment (Maximum 30 Points)**\\n\\n*   **(30 Points): Strong Domain and Content Alignment:** Domain name strongly and unambiguously suggests a category, and the website content consistently and explicitly reinforces that category.  They tell the same clear story.\\n*   **(15 Points): Partial Domain and Content Alignment:** Domain name and content generally point towards the same category, but the alignment might be less direct, slightly ambiguous, or require some interpretation to connect them.\\n*   **(0 Points): Domain-Content Mismatch or No Alignment:** Domain name suggests one thing, but the content is unclear, suggests something different, or there\\'s no clear connection between the domain and the content\\'s apparent purpose.\\n\\n#### **III. Content Clarity and Unambiguity (Maximum 20 Points)**\\n\\n*   **(20 Points): Unambiguous and Explicit Content:** The website content is very clear, direct, and leaves virtually no room for interpretation. It unambiguously falls into one of the defined categories.\\n*   **(10 Points): Content Requires Some Interpretation:** The content generally points to a category, but requires some interpretation to confidently assign it.  There might be subtle hints, implied meanings, or a need to infer the primary purpose.\\n*   **(0 Points): Ambiguous or Conflicting Content:** The website content is vague, contradictory, or could be reasonably interpreted in multiple ways, making it difficult to confidently assign a category.\\n\\n#### **IV. Category Indicator Strength (Maximum 10 Points)**\\n\\n*   **(10 Points): Multiple Strong Category Indicators:** Presence of numerous strong and clear indicators for a specific category throughout the domain and content (e.g., for Pornography: explicit keywords, descriptions of sexual acts, calls to action to view adult content, age verification prompts).\\n*   **(5 Points): Some Category Indicators Present:** Presence of a few indicators for a category, but they are not overwhelmingly strong or numerous.\\n*   **(0 Points): Lack of Category Indicators:** Few or no clear indicators for any of the defined categories are present in the domain and content.\\n\\n#### **Calculation:**\\n\\n1.  For each of the four sections (I-IV), assess the website and select the point value that best describes the presence of the described factors.\\n2.  Sum up the points from all four sections.\\n3.  The total sum represents the confidence level in percentage (%).\\n\\n#### **Confidence Level Ranges (for reference - already implicitly defined by points):**\\n\\n*   **High Confidence (80-100 Points):**  Strong evidence across multiple factors pointing clearly to a category.\\n*   **Medium Confidence (50-79 Points):** Moderate evidence, some ambiguity or less directness in indicators.\\n*   **Low Confidence (0-49 Points):** Weak or conflicting evidence, high uncertainty about the correct category.\\n\\n#### **Example:**\\n\\nLet\\'s say you are classifying `lucky-slots-online.com` with content about slot games and bonuses.\\n\\n*   **I. Keyword Strength:** Strong keywords in both Domain and Content (e.g., \"slots,\" \"online,\" \"win,\" \"bonuses\") - **25 Points**\\n*   **II. Domain-Content Alignment:** Domain and content strongly align with Gambling - **30 Points**\\n*   **III. Content Clarity:** Content is very clear about gambling activities - **20 Points**\\n*   **IV. Category Indicators:** Multiple indicators of gambling (games, bonuses, calls to action) - **10 Points**\\n\\n**Total Points: 25 + 30 + 20 + 10 = 85 Points.  Confidence: 85%**\\n\\n#### **Using this Point System:**\\n\\nWhen generating the \"reason\" for your classification, you can now also briefly mention the points you assigned for each section to justify the final confidence score. For example:\\n\\n```json\\n{\\n  \"answer\": 1,\\n  \"classification\": \"Gambling\",\\n  \"reason\": \"Strong keywords in domain and content (25 pts), strong domain-content alignment (30 pts), clear gambling content (20 pts), multiple category indicators (10 pts). Total 85 points.\",\\n  \"confidence\": 85\\n}\\n```\\n\\n### **Output Requirements: STRICTLY ADHERE TO JSON FORMAT**\\n\\nFor each website, you **MUST** provide your classification in the following **JSON format ONLY**.  **No other format is acceptable.**\\n\\n```json\\n{\\n  \"answer\": (integer: 0, 1, 2, or 3),\\n  \"classification\": (string: \"Benign\", \"Gambling\", \"Pornography\", or \"Harmful\"),\\n  \"reason\": (string: \"Brief explanation of the classification using keywords and hints from the domain and content.\"),\\n  \"confidence\": (integer: 0 to 100, \"Level of confidence in the classification\")\\n}\\n```\\n\\n**Example Input and Expected Output:**\\n\\n**1st Sample**\\n\\n**Input Data:**\\n\\n```\\nDomain: news-today.info\\nContent: Welcome to News Today! Get the latest breaking news, top stories, and in-depth analysis from around the world. Covering politics, business, technology, sports, and culture. Stay informed with News Today - your source for reliable journalism.\\n```\\n\\n**Expected Output:**\\n\\n```json\\n{\\n  \"answer\": 0,\\n  \"classification\": \"Benign\",\\n  \"reason\": \"Domain \\'news-today.info\\' and content mention \\'breaking news,\\' \\'top stories,\\' \\'analysis,\\' \\'reliable journalism,\\' indicating a general information/news website. Strong keywords in domain and content (35 pts), strong domain-content alignment (30 pts), unambiguous content (20 pts), some category indicators (5 pts). Total 90 points.\",\\n  \"confidence\": 90\\n}\\n```\\n\\n**2nd Sample:**\\n\\n**Input Data:**\\n\\n```\\nDomain: lucky-slots-online.com\\nContent:  Spin to win big at Lucky Slots Online! Play hundreds of exciting slot games, claim your bonuses, and join the fun.  Licensed and regulated for your safety. 24/7 customer support available. Join now and get 100 free spins!\\n```\\n\\n**Expected Output:**\\n\\n```json\\n{\\n  \"answer\": 1,\\n  \"classification\": \"Gambling\",\\n  \"reason\": \"Domain \\'lucky-slots-online.com\\' and content include keywords like \\'slots,\\' \\'win,\\' \\'casino,\\' \\'bonuses,\\' \\'free spins,\\' indicating a gambling website.\",\\n  \"confidence\": 100\\n}\\n```\\n\\n**3rd Sample**\\n\\n**Input Data:**\\n\\n```\\nDomain: adult-pleasures.net\\nContent:  Experience the hottest adult entertainment online. Unlimited access to exclusive videos and photos. 18+ only. Join our community of pleasure seekers today!\\n```\\n\\n**Expected Output:**\\n\\n```json\\n{\\n  \"answer\": 2,\\n  \"classification\": \"Pornography\",\\n  \"reason\": \"Domain \\'adult-pleasures.net\\' and content include explicit terms like \\'adult entertainment,\\' \\'exclusive videos,\\' \\'photos,\\' \\'18+ only,\\' and \\'pleasure seekers,\\' indicating a pornography website. Strong keywords in both domain and content (25 pts), strong domain-content alignment (30 pts), unambiguous content (20 pts), multiple category indicators (10 pts). Total 85 points.\",\\n  \"confidence\": 85\\n}\\n```\\n**4th Sample**\\n\\n**Input Data:**\\n\\n```\\nDomain: project420.com\\nContent:  Welcome to Project420.com an ongoing community marijuana, hemp search engine and your gateway to 420 products, services and information from all over the world. Marijuana seeds, super bongs, high tech growing marijuana books, contests, communities, cool people and tons of 420 fun.  Potent marijuana websites are added frequently.  Let\\'s help each other grow.  Use the table of contents located to the left and begin your search of 420 world wide websites.\\n```\\n\\n**Expected Output:**\\n\\n```json\\n{\\n  \"answer\": 3,\\n  \"classification\": \"Harmful\",\\n  \"reason\": \"Domain \\'project420.com\\' and content include keywords like \\'marijuana seeds,\\' \\'growing marijuana,\\' and \\'420 products,\\' indicating promotion of illegal drugs under Indonesian law (UU ITE). Strong keywords in content (25 pts), Partial Domain and Content Alignment (15 pts), clear harmful intent (20 pts), multiple indicators (10 pts). Total 70 points.\",\\n  \"confidence\": 70\\n}\\n```\\n**Execution:**\\nProcess the provided website data (input fields: `Domain`, `Content`). Apply the classification categories, definitions, and confidence point system accurately. Generate the mandatory JSON output for each entry. Begin classification now.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nClassify the given URL as 0 (benign), 1 (gambling), 2 (pornography), or 3 (harmful). Output MUST be JSON.\\n\\nDomain: adevotedslave.blogspot.com, Content: \"Delicious Debauchery If You arenâ€™t over the age 18 (21 in some areas) then please leave. If You are offended by sex, BDSM, phone sex or brutal honesty then this isn\\'t the place for You. FRIDAY, JUNE 08, 2007 Why Iâ€™ll never be a full lesbianâ€¦ You know, it doesnâ€™t seem to matter what I am using or what position I am in. Iâ€™ve tried it with dildos, vibes, my gear shift knob, my fingers, and miscellaneous household objects, with just about anything and every thing I can think of. Iâ€™ve done it on my hands and knees on my back, with one leg up. Iâ€™ve tried putting the base on the floor and bouncing up and down. Iâ€™ve put it up against a wall and pushed against it. It doesnâ€™t matter. Nothing that I do makes it so that I can fuck myself hard enough to make it feel just right. Nothing can take me to that place where I am balancing between the pleasure of being fucked and the pain of having a cock battering my insides. Of course, when Iâ€™m trying to simulate hard fucking it still feels good, but itâ€™s that kind of feeling you get when you are almost there, but not quite. You know where you want to go but you just canâ€™t get there. Itâ€™s frustrating as hell. Besides, I have never actually had a toy, or object Iâ€™ve converted into a toy, thatâ€™s felt like a real cock anyway. They all just feel like random objects that fall short of the glory that is a real, hard, throbbing, piece of flesh designed for fucking. Of course, if thereâ€™s some woman out there whoâ€™s willing to try to convert me into a full fledged lesbian anyway, Iâ€™m more than willing to submit to that kind of training. Who knows? A woman with a strap on may be able to fuck me just like I like. Of course, Iâ€™d not refuse returning the favor. It could be a mutually beneficial experiment. POSTED BY DEIDRE AT 11:13 AM 2 COMMENTS SATURDAY, APRIL 28, 2007 Bruised and Battered For some reason I think that the depth of my pussy fluctuates. Sometimes when Masterâ€™s cock slides inside of me it is the perfect fit. The head hits in just the... en melted apart. A puff of smoke flew up, and there was another familiar sensation... the smell of burned meat. Again the heat, with a dirty orange light where the flame burned away the bits of tissue stuck to the wire. Again the application, the shudder, the pop, the hiss, the smoke. Around the stencil he went, carefully watching the brand, lining up the strikes. As the skin opens along the brand\\'s outline, it shifts. About halfway around, he started almost freehanding, using the stencil as a reminder of what he wanted, not as a guide. Then with the outline complete, and even, he used its angles as a reference for the final strikes down the middle. There were ten strikes in all. Ten times the iron glowed, ten times it lowered to her helpless flesh. Ten times she moaned as her love for me was burned into her very body. As I continued my research I rediscovered Fakirâ€™s site and the process of using an electro-cautery pencil instead of using the striking method with heated ribbons of steel. I showed a few examples to Master, including a photo of hisdevotionâ€™s back. He asked how one goes about getting an electro-cautery pencil. Until that moment it never even occurred to me that a person outside of the medical profession could just go and buy one. Well, for less than a hundred bucks one can buy a battery operated one with various different tips. Something wonderful happened as I scrolled through all of the options for this tool. I began reading in the descriptions that they get up to 2200 degrees Fahrenheit. Instead of the fear I expected to feel at such a number I felt the nervous flutters of excitement. If Master decides to go this direction, and have His mark of ownership burned into my skin in this fashion, I will have 2200 degrees focused on my skin, burning me, marking me bit by bit. This makes me incredibly aroused. Perhaps I have the makings of a pain slut afterall. POSTED BY DEIDRE AT 1:43 PM 0 COMMENTS TUESDAY, MARCH 13, 2007 masks Iâ€™ve said before that my relationship with Master and the trust and honesty that is the foundation of that relationship has made me more fully myself than I ever have been before. I am more aware of the different aspects of myself and I am able to lie them all out on the table to be poked at and prodded by any stranger who happens by. On the other hand there are those for whom I must wear certain masks. My relationship with Master might have inspired an intense honesty with myself and with Him, as well as with those who can accept us this way and those whose judgement doesnâ€™t matter, but itâ€™s also forced me to be more dishonest than ever to those around me, my neighbors, friends and family. I have been asked by potential sisters, by friends and by callers about how the world sees me. What does Master let the neighbors see? His friends? My friends? My family? His family? Itâ€™s all kind of complicated. The neighbors/His friends: * My neighbors see a 28 year old girl who is living with a 53 year old man. They see the 2 of us happily interacting with each other. He is very active in our neighborhood community. I am not. I occasionally wave to the neighbors or have a conversation with them and most of the time they say something to the effect of, \"Itâ€™s been a while. How have you been?\" Most of them are nice people, but I have little desire to interact with them. They know that I am a phone sex operator and most of them are intrigued. They do not know that I am a slave but there are probably quite a few who have observed that I donâ€™t make any decisions of importance. My friends: * My friends all know just about everything there is to know. Friends that I consider to be mine (as opposed to those that I know because of Master) are basically those from the internet. This includes a few people from collarme and other personals sites but the vast majority is made up of people from LiveJournal. LiveJournal is where all of my meaningful social interaction takes place, as sad as that may seem. There just arenâ€™t a whole lot of people like me nearby and being friends with a girl whoâ€™s first priority is never friendships can be trying. His family: * Masterâ€™s brother, K. He is aware of the basics of the dynamics between Master and myself however itâ€™s never discussed with him and itâ€™s never thrown in his face. We donâ€™t play or fuck in front of K. Iâ€™ve never been loaned to K. Master and I have discussed it and if K is anything heâ€™s probably more submissive than dominant. K knows that I am a phone sex operator. I think he may have heard me on occasion when I am taking calls. * The rest of Masterâ€™s family. He has one of those families that has reunions every year. The patriarch of the family is in his 90s and still kicking. I havenâ€™t met everyone yet, but Iâ€™ve met the ones that are either closest or that Master likes the most. They have opened their arms and accepted me, making me an honorary â€“insert Masterâ€™s family name here- One of them told me over thanksgiving that she has never seen Master as happy as he is now and she thinks that I am to thank for that. What higher compliment can someone pay me than that? My Family: * My sister, E, and I used to be very close. Weâ€™re not anymore though. When I went to her house last summer I had just come from my fathers and wasnâ€™t wearing my collar. The first night I was getting ready to go out with her and my mother and put it back on. Her reaction was that my necklace didnâ€™t match my outfit and I should take the jewelry off. I refused explaining that Master (I used his first name) gave it to me and I hadnâ€™t really had it off since except for when I visited dad. I think she started to get the idea at that point. She knew a little before then, but I think the image of me collared finished off any of the blank parts in her imagination of how I was living my life. I donâ€™t think she approves. We havenâ€™t spoken since then. Iâ€™m not sure how much my lifestyle has to do with that though. * My mother knows the pieces and details that I think sh...  get enough. Sheâ€™s become my newest addiction. I lick the juice of her squirt from my arm and slide my fingers from her into my mouth. I love that taste. Outside the sun is beginning to rise. Weâ€™ve been lost in each other for the entire night. The magic begins to dissipate. We get dressed once again shy and nervous. The blush on my face doesnâ€™t stop me from telling her how much I enjoyed the night. It turns out that she did too and that we both want to do it again. Soon. POSTED BY DEIDRE AT 1:59 PM 0 COMMENTS Older Posts Home Subscribe to: Posts (Atom) ABOUT DEIDRE DEIDRE STRADDLING THE LINE BETWEEN FANTASY AND REALITY deidre is a 28 yo lifestyle slave, phone sex operator and fetish model. she is happily owned. VIEW MY COMPLETE PROFILE LINKS 101 Things about deidre NITEFLIRT delicious debauchery Join for Free What is NiteFlirt? MP3 RECORDINGS The Holy Fuck **fetish sample Gender Blender **hypnosis sample How to Get Out of a Ticket **fetish sample Gym Discipline **fetish sample French Maid **fetish sample Lesbian Strap-on BDSM **fetish sample Lesbian Tickle Bondage **fetish sample Isabella\\'s Sex Slave **hypnosis sample Gagged By Goddess **fetish sample Boarding School Humiliation **fetish sample RECORDINGS (BY THE MINUTE) rates and descriptions deidre\\'s daily prayer deidre gets face fucked equipment sampler deidre\\'s discipline barking cough tickle torture psalm 23 (deidre style) a steamy shower & my fav toy PHOTO SETS rates and descriptions teddy bears & coloring books deidre\\'s puppy training photo sampler bondage the golden set deidre\\'s naughty picnic deidre in distress foot bondage PODCASTS Session 2 Interview with Miss Isabella Session 1 WISHFUL THINKING amazon wishlist deidre\\'s corset fund LABELS questions (13) NiteFlirt (12) mp3 (11) calls (6) gifts (5) music (5) pics (2) podcast (2) meme (1) quotes (1) BLOG ARCHIVE â–¼ 2007 (41) â–¼ JUNE (1) â–¼ JUN 08 (1) WHY Iâ€™LL NEVER BE A FULL LESBIANâ€¦ â–º APRIL (2) â–º MARCH (6) â–º FEBRUARY (11) â–º JANUARY (21) â–º 2006 (117) â–º 1978 (2)\"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<think>\\nOkay, I need to classify this website into one of the four categories: Benign, Gambling, Pornography, or Harmful. Let\\'s start by looking at the domain and content provided.  The domain is adevotedslave.blogspot. com. The word \"slavery\" in the domain could be a red flag because it might relate to harmful activities like human trafficking. But I should also consider if it\\'s used in a different context, such as BDSM or kink communities which are more about consensual adult content.  Looking at the content, there are several posts discussing BDSM practices, phone sex, and explicit sexual scenarios. For example, one post talks about trying various objects for self-pleasure and another describes a session involving masks and domination. There\\'s also mention of being a \"lifestyle slave\" and a \"phone sex operator,\" which suggests the site is focused on adult content.  The content includes terms like \"BDSM,\" \"fetish,\" \"bondage,\" and explicit descriptions of sexual acts. These keywords are strong indicators of Pornography because they relate to adult themes and explicit material intended for arousal.  However, I should check if it falls under Harmful instead. The website doesn\\'t seem to promote illegal activities like drug sales or cybercrime. It\\'s more about consensual adult content, which would typically fall under Pornography rather than Harmful unless there are elements of non-consent or exploitation, which aren\\'t clearly present here.  The domain and content align well with Pornography because the focus is on explicit sexual content and fetishes. There are no strong indicators pointing towards Gambling or Benign categories. The content is unambiguous in its adult themes, so it doesn\\'t seem to be a case of harmful activities outside the scope of Pornography.  In terms of confidence assessment: - Keyword Strength: Strong keywords like \"fetish,\" \"bondage,\" and explicit sexual descriptions are present both in the domain and content. - Domain-Content Alignment: The domain suggests a BDSM or slavery theme, which is reinforced by the content discussing explicit adult scenarios. - Content Clarity: The content is very clear about its focus on adult entertainment and fetishes without ambiguity. - Category Indicators: Multiple indicators such as explicit sexual descriptions, use of terms like \"phone sex operator,\" and detailed accounts of BDSM practices.  Based on these factors, I\\'m confident that this website falls under the Pornography category with a high confidence score.\\n</think>\\n```json\\n{\\n  \"answer\": 2,\\n  \"classification\": \"Pornography\",\\n  \"reason\": \"The domain \\'adevotedslave. blogspot.com\\' and content include explicit terms like \\'BDSM,\\' \\'fetish,\\' \\'bondage,\\' and detailed descriptions of sexual acts, indicating a focus on adult entertainment. Strong keywords in both domain and content (25 pts), strong domain-content alignment (30 pts), unambiguous content (20 pts), multiple category indicators (10 pts). Total 85 points.\",\\n  \"confidence\": 85\\n}\\n```<|eot_id|>'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict['test'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d4bd38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = NVIDIA GeForce RTX 3090 Ti. Max memory = 23.551 GB.\n",
      "3.441 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "# @title Show current memory stats\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f793d683",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: conversations, text. If conversations, text are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 33,128 | Num Epochs = 2 | Total steps = 2,100\n",
      "O^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 4 x 1) = 16\n",
      " \"-____-\"     Trainable parameters = 97,255,424/3,000,000,000 (3.24% trained)\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='130' max='2100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 130/2100 1:56:33 < 29:53:56, 0.02 it/s, Epoch 0.06/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>7.323700</td>\n",
       "      <td>5.390213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>6.707500</td>\n",
       "      <td>4.619384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>5.357600</td>\n",
       "      <td>2.803724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.718900</td>\n",
       "      <td>0.924320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.454800</td>\n",
       "      <td>0.048286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.046100</td>\n",
       "      <td>0.025213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.042200</td>\n",
       "      <td>0.018148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>0.011971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.349800</td>\n",
       "      <td>0.011343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.152300</td>\n",
       "      <td>0.010476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>0.010302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>0.009724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: conversations, text. If conversations, text are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 134\n",
      "  Batch size = 1\n",
      "Unsloth: Not an error, but LlamaForCausalLM does not accept `num_items_in_batch`.\n",
      "Using gradient accumulation will be very slightly less accurate.\n",
      "Read more on gradient accumulation issues here: https://unsloth.ai/blog/gradient\n",
      "The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: conversations, text. If conversations, text are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 134\n",
      "  Batch size = 1\n",
      "The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: conversations, text. If conversations, text are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 134\n",
      "  Batch size = 1\n",
      "The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: conversations, text. If conversations, text are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 134\n",
      "  Batch size = 1\n",
      "The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: conversations, text. If conversations, text are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 134\n",
      "  Batch size = 1\n",
      "The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: conversations, text. If conversations, text are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 134\n",
      "  Batch size = 1\n",
      "The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: conversations, text. If conversations, text are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 134\n",
      "  Batch size = 1\n",
      "The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: conversations, text. If conversations, text are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 134\n",
      "  Batch size = 1\n",
      "The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: conversations, text. If conversations, text are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 134\n",
      "  Batch size = 1\n",
      "The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: conversations, text. If conversations, text are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 134\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to outputs/checkpoint-100\n",
      "loading configuration file config.json from cache at /home/fishmon/.cache/huggingface/hub/models--unsloth--llama-3.2-3b-instruct-bnb-4bit/snapshots/aae9d3e87a2c47cc465b6980017a05e1d1d61c8c/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 24,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pad_token_id\": 128004,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"quantization_config\": {\n",
      "    \"_load_in_4bit\": true,\n",
      "    \"_load_in_8bit\": false,\n",
      "    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
      "    \"bnb_4bit_quant_storage\": \"uint8\",\n",
      "    \"bnb_4bit_quant_type\": \"nf4\",\n",
      "    \"bnb_4bit_use_double_quant\": true,\n",
      "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
      "    \"llm_int8_has_fp16_weight\": false,\n",
      "    \"llm_int8_skip_modules\": [\n",
      "      \"lm_head\",\n",
      "      \"multi_modal_projector\",\n",
      "      \"merger\",\n",
      "      \"modality_projection\"\n",
      "    ],\n",
      "    \"llm_int8_threshold\": 6.0,\n",
      "    \"load_in_4bit\": true,\n",
      "    \"load_in_8bit\": false,\n",
      "    \"quant_method\": \"bitsandbytes\"\n",
      "  },\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.51.3\",\n",
      "  \"unsloth_fixed\": true,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: conversations, text. If conversations, text are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 134\n",
      "  Batch size = 1\n",
      "The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: conversations, text. If conversations, text are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 134\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer_stats \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# checkpoint_path = \"./outputs/checkpoint-700\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# if os.path.exists(checkpoint_path):\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#     trainer.train(resume_from_checkpoint=checkpoint_path)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# else:\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#     print(f\"Warning: Checkpoint {checkpoint_path} not found. Starting from scratch.\")\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/transformers/trainer.py:2245\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2243\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2246\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2250\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<string>:314\u001b[0m, in \u001b[0;36m_fast_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n",
      "File \u001b[0;32m<string>:31\u001b[0m, in \u001b[0;36m_unsloth_training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n",
      "File \u001b[0;32m~/AJ/LLM-Finetuning/Malicious-Web/unsloth_compiled_cache/UnslothSFTTrainer.py:748\u001b[0m, in \u001b[0;36m_UnslothSFTTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_loss\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, inputs, return_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, num_items_in_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 748\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_outputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mreturn_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    753\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    754\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/unsloth/models/_utils.py:1029\u001b[0m, in \u001b[0;36m_unsloth_pre_compute_loss\u001b[0;34m(self, model, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1023\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning_once(\n\u001b[1;32m   1024\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsloth: Not an error, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept `num_items_in_batch`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\\\n\u001b[1;32m   1025\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing gradient accumulation will be very slightly less accurate.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\\\n\u001b[1;32m   1026\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead more on gradient accumulation issues here: https://unsloth.ai/blog/gradient\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1027\u001b[0m     )\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m-> 1029\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_compute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/transformers/trainer.py:3801\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3799\u001b[0m         loss_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_items_in_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_items_in_batch\n\u001b[1;32m   3800\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloss_kwargs}\n\u001b[0;32m-> 3801\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3802\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1845\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[1;32m   1844\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1845\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1847\u001b[0m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[1;32m   1848\u001b[0m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[1;32m   1849\u001b[0m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[1;32m   1850\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1793\u001b[0m, in \u001b[0;36mModule._call_impl.<locals>.inner\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1790\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m BackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1791\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1793\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1795\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1796\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1797\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1798\u001b[0m     ):\n\u001b[1;32m   1799\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/accelerate/utils/operations.py:814\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/accelerate/utils/operations.py:802\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/torch/amp/autocast_mode.py:44\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 44\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/torch/_compile.py:32\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m     disable_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)\n\u001b[1;32m     30\u001b[0m     fn\u001b[38;5;241m.\u001b[39m__dynamo_disable \u001b[38;5;241m=\u001b[39m disable_fn\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdisable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:745\u001b[0m, in \u001b[0;36mDisableContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    741\u001b[0m prior_skip_guard_eval_unsafe \u001b[38;5;241m=\u001b[39m set_skip_guard_eval_unsafe(\n\u001b[1;32m    742\u001b[0m     _is_skip_guard_eval_unsafe_stance()\n\u001b[1;32m    743\u001b[0m )\n\u001b[1;32m    744\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    747\u001b[0m     _maybe_set_eval_frame(prior)\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/unsloth/models/llama.py:1200\u001b[0m, in \u001b[0;36mPeftModelForCausalLM_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, num_logits_to_keep, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39m_disable_dynamo\n\u001b[1;32m   1185\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mPeftModelForCausalLM_fast_forward\u001b[39m(\n\u001b[1;32m   1186\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1198\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1199\u001b[0m ):\n\u001b[0;32m-> 1200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1209\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_logits_to_keep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_logits_to_keep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_to_keep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlogits_to_keep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1211\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1212\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/peft/tuners/tuners_utils.py:193\u001b[0m, in \u001b[0;36mBaseTuner.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any):\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/unsloth/models/llama.py:1043\u001b[0m, in \u001b[0;36mCausalLM_fast_forward.<locals>._CausalLM_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, num_logits_to_keep, logits_to_keep, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1041\u001b[0m     \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39m_has_no_labels \u001b[38;5;241m=\u001b[39m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1043\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/unsloth/models/llama.py:858\u001b[0m, in \u001b[0;36mLlamaModel_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, *args, **kwargs)\u001b[0m\n\u001b[1;32m    856\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m custom_forward\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 858\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_custom_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_reentrant\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreserve_rng_state\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    867\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    869\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/torch/_compile.py:32\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m     disable_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)\n\u001b[1;32m     30\u001b[0m     fn\u001b[38;5;241m.\u001b[39m__dynamo_disable \u001b[38;5;241m=\u001b[39m disable_fn\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdisable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:745\u001b[0m, in \u001b[0;36mDisableContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    741\u001b[0m prior_skip_guard_eval_unsafe \u001b[38;5;241m=\u001b[39m set_skip_guard_eval_unsafe(\n\u001b[1;32m    742\u001b[0m     _is_skip_guard_eval_unsafe_stance()\n\u001b[1;32m    743\u001b[0m )\n\u001b[1;32m    744\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    747\u001b[0m     _maybe_set_eval_frame(prior)\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/unsloth_zoo/gradient_checkpointing.py:747\u001b[0m, in \u001b[0;36munsloth_checkpoint\u001b[0;34m(function, use_reentrant, context_fn, determinism_check, debug, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m context_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m noop_context_fn \u001b[38;5;129;01mor\u001b[39;00m debug \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    743\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    744\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing `context_fn` or `debug` is only supported when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    745\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_reentrant=False.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    746\u001b[0m         )\n\u001b[0;32m--> 747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mUnslothCheckpointFunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    749\u001b[0m     gen \u001b[38;5;241m=\u001b[39m _checkpoint_without_reentrant_generator(\n\u001b[1;32m    750\u001b[0m         function, preserve, context_fn, determinism_check, debug, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    751\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/torch/autograd/function.py:575\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    574\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    583\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/unsloth_zoo/gradient_checkpointing.py:463\u001b[0m, in \u001b[0;36mUnslothCheckpointFunction.forward\u001b[0;34m(ctx, run_function, preserve_rng_state, *args)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ctx\u001b[38;5;241m.\u001b[39m_requires_gradient: ctx\u001b[38;5;241m.\u001b[39msave_for_backward(\u001b[38;5;241m*\u001b[39mtensor_inputs)\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 463\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mrun_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_gpu_buffer: MAIN_STREAM\u001b[38;5;241m.\u001b[39mwait_stream(EXTRA_STREAM)\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/unsloth/models/llama.py:855\u001b[0m, in \u001b[0;36mLlamaModel_fast_forward.<locals>.create_custom_forward.<locals>.custom_forward\u001b[0;34m(*inputs)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcustom_forward\u001b[39m(\u001b[38;5;241m*\u001b[39minputs):\n\u001b[0;32m--> 855\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/unsloth/models/llama.py:543\u001b[0m, in \u001b[0;36mLlamaDecoderLayer_fast_forward\u001b[0;34m(self, hidden_states, causal_mask, attention_mask, position_ids, past_key_value, output_attentions, use_cache, padding_mask, position_embeddings, *args, **kwargs)\u001b[0m\n\u001b[1;32m    541\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    542\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m fast_rms_layernorm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm, hidden_states)\n\u001b[0;32m--> 543\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    554\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    556\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/unsloth/models/llama.py:424\u001b[0m, in \u001b[0;36mLlamaAttention_fast_forward\u001b[0;34m(self, hidden_states, causal_mask, attention_mask, position_ids, past_key_value, output_attentions, use_cache, padding_mask, position_embeddings, *args, **kwargs)\u001b[0m\n\u001b[1;32m    417\u001b[0m         cos, sin \u001b[38;5;241m=\u001b[39m rotary_emb(V, seq_len \u001b[38;5;241m=\u001b[39m kv_seq_len)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;66;03m# Q, K = (\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m#     fast_rope_embedding(Q, K, cos, sin)\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;66;03m#     if position_ids is None\u001b[39;00m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;66;03m#     else inplace_rope_embedding(Q, K, cos, sin, position_ids)\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[0;32m--> 424\u001b[0m Q, K \u001b[38;5;241m=\u001b[39m \u001b[43mfast_rope_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    427\u001b[0m     K \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([past_key_value[\u001b[38;5;241m0\u001b[39m], K], dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:745\u001b[0m, in \u001b[0;36mDisableContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    741\u001b[0m prior_skip_guard_eval_unsafe \u001b[38;5;241m=\u001b[39m set_skip_guard_eval_unsafe(\n\u001b[1;32m    742\u001b[0m     _is_skip_guard_eval_unsafe_stance()\n\u001b[1;32m    743\u001b[0m )\n\u001b[1;32m    744\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    747\u001b[0m     _maybe_set_eval_frame(prior)\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/unsloth/kernels/rope_embedding.py:157\u001b[0m, in \u001b[0;36mfast_rope_embedding\u001b[0;34m(Q, K, cos, sin)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mcompiler\u001b[38;5;241m.\u001b[39mdisable\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfast_rope_embedding\u001b[39m(Q, K, cos, sin):\n\u001b[1;32m    156\u001b[0m     Q \u001b[38;5;241m=\u001b[39m Fast_RoPE_Embedding\u001b[38;5;241m.\u001b[39mapply(Q\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m), cos, sin)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 157\u001b[0m     K \u001b[38;5;241m=\u001b[39m \u001b[43mFast_RoPE_Embedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mK\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msin\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Q, K\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/torch/autograd/function.py:575\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    574\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    583\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/unsloth/kernels/rope_embedding.py:104\u001b[0m, in \u001b[0;36mFast_RoPE_Embedding.forward\u001b[0;34m(ctx, Q, cos, sin)\u001b[0m\n\u001b[1;32m    101\u001b[0m n_groups : \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m div \u001b[38;5;241m+\u001b[39m (mod \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch_cuda_device(Q\u001b[38;5;241m.\u001b[39mdevice):\n\u001b[0;32m--> 104\u001b[0m     \u001b[43m_rope_embedding\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m          \u001b[49m\u001b[43mQ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[43mQ\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43msin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mBACKWARD_PASS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mBLOCK_SIZE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mBLOCK_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_warps\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_warps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m ctx\u001b[38;5;241m.\u001b[39mBLOCK_SIZE \u001b[38;5;241m=\u001b[39m BLOCK_SIZE\n\u001b[1;32m    115\u001b[0m ctx\u001b[38;5;241m.\u001b[39mnum_warps  \u001b[38;5;241m=\u001b[39m num_warps\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/triton/runtime/jit.py:330\u001b[0m, in \u001b[0;36mKernelInterface.__getitem__.<locals>.<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, grid) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    325\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;124;03m    A JIT function is launched with: fn[grid](*args, **kwargs).\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;124;03m    Hence JITFunction.__getitem__ returns a callable proxy that\u001b[39;00m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;124;03m    memorizes the grid.\u001b[39;00m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarmup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/triton/runtime/autotuner.py:385\u001b[0m, in \u001b[0;36mHeuristics.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m v, heur \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    384\u001b[0m     kwargs[v] \u001b[38;5;241m=\u001b[39m heur({\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marg_names, args)), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs})\n\u001b[0;32m--> 385\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/triton/runtime/jit.py:653\u001b[0m, in \u001b[0;36mJITFunction.run\u001b[0;34m(self, grid, warmup, *args, **kwargs)\u001b[0m\n\u001b[1;32m    651\u001b[0m     \u001b[38;5;66;03m# launch kernel\u001b[39;00m\n\u001b[1;32m    652\u001b[0m     launch_metadata \u001b[38;5;241m=\u001b[39m kernel\u001b[38;5;241m.\u001b[39mlaunch_metadata(grid, stream, \u001b[38;5;241m*\u001b[39mnon_constexpr_vals)\n\u001b[0;32m--> 653\u001b[0m     \u001b[43mkernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrid_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpacked_metadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlaunch_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m               \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompiledKernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch_enter_hook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompiledKernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch_exit_hook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnon_constexpr_vals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m kernel\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/triton/backends/nvidia/driver.py:444\u001b[0m, in \u001b[0;36mCudaLauncher.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 444\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._post_run_cell_hook of <wandb.sdk.wandb_init._WandbInit object at 0x746ae6dafe90>> (for post_run_cell), with arguments args (<ExecutionResult object at 746ae6df8490, execution_count=22 error_before_exec=None error_in_exec= info=<ExecutionInfo object at 746ae6df86d0, raw_cell=\"trainer_stats = trainer.train()\n",
      "\n",
      "# checkpoint_path..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell://ssh-remote%2B100.77.86.156/home/fishmon/AJ/LLM-Finetuning/Malicious-Web/unsloth_netpro.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/wandb/sdk/wandb_init.py:614\u001b[0m, in \u001b[0;36m_WandbInit._post_run_cell_hook\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresuming backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 614\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/wandb/sdk/interface/interface.py:779\u001b[0m, in \u001b[0;36mInterfaceBase.publish_resume\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    778\u001b[0m     resume \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mResumeRequest()\n\u001b[0;32m--> 779\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py:293\u001b[0m, in \u001b[0;36mInterfaceShared._publish_resume\u001b[0;34m(self, resume)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m, resume: pb\u001b[38;5;241m.\u001b[39mResumeRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    292\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(resume\u001b[38;5;241m=\u001b[39mresume)\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py:39\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_record_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py:174\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    172\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrequest_id \u001b[38;5;241m=\u001b[39m record\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mmailbox_slot\n\u001b[1;32m    173\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[0;32m--> 174\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py:154\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: spb\u001b[38;5;241m.\u001b[39mServerRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py:151\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    149\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 151\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/unsloth_env/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "trainer_stats = trainer.train()\n",
    "\n",
    "# checkpoint_path = \"./outputs/checkpoint-700\"\n",
    "# if os.path.exists(checkpoint_path):\n",
    "#     trainer.train(resume_from_checkpoint=checkpoint_path)\n",
    "# else:\n",
    "#     print(f\"Warning: Checkpoint {checkpoint_path} not found. Starting from scratch.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2204b2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this before the automatic evaluation at step 500\n",
    "trainer.evaluate(eval_dataset=trainer.eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7576f61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d15042a",
   "metadata": {},
   "outputs": [],
   "source": [
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "used_percentage = round(used_memory         /max_memory*100, 3)\n",
    "lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n",
    "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
    "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
    "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
    "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
    "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
    "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6fc928",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a15012a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fishmon/.conda/envs/unsloth_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 2.5.1 with CUDA 1201 (you have 2.6.0+cu124)\n",
      "    Python  3.11.10 (you have 3.11.11)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Failed to patch Gemma3ForConditionalGeneration.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 3090 Ti. Num GPUs = 1. Max memory: 23.551 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.3.19 patched 28 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\nYou are an Expert Website Classifier tasked with categorizing websites (using provided Domain & Content) into distinct categories: **0 - Benign**, **1 - Gambling**, **2 - Pornography**, or **3 - Harmful**. Output strict JSON including classification, reason, and a point-based confidence score (0-100). This aids a sophisticated website prediction system for digital safety.\\n\\n### **Categories & Definitions:**\\n\\n-   **0 - Benign:** General info, news, entertainment, services, e-commerce, educational sites, blogs, informational pages, and general entertainment sites. No gambling/porn themes.\\n    -   **Includes:** Educational discussion of sensitive topics (drugs, gambling, adult, illegal), suggestive content (dating, lingerie) *without* explicit material, drugs for educational or news purposes (e.g., addiction recovery, medical cannabis research).\\n\\n-   **1 - Gambling:** Promotes/facilitates betting, casino, poker, lottery, wagering. Includes online betting platforms, casinos, poker sites, lottery sites, and any website that encourages or provides means for users to wager money on games of chance or skill.\\n    -   **Keywords:** betting, casino, poker, odds, jackpot, slots, roulette, judi, slot gacor, togel, similar gambling-related terminology within their domain name or content.\\n    \\n-   **2 - Pornography:** These are websites that contain explicit sexual content intended to cause arousal. Explicit sexual content (images, videos, text) for arousal. Immoral content (bestiality, child exploitation). or links to such materials. \\n    -   **Keywords:** porn, bokep, sex, xxx, adult, nude, erotic, explicit video/photo.\\n\\n- **3 - Harmful**: Websites that does not fall to Benign, Gambling, and Pornography category. These websites engage in or promote activities harmful to users or violating laws/regulations, including:\\n    - Malware Distribution: Hosting/downloading computer viruses, worms, ransomware, spyware, etc.\\n    - Cybercrime: Phishing kits, hacking tools, stolen data markets, carding forums.\\n    - Extremism & Terrorism: Content inciting violence, extremist ideologies, or terrorist recruitment.\\n    - Violations of Indonesian Law:\\n        - Insults, defamation, blackmail, or threats.\\n        - Hoaxes/misleading news, hate speech, or incitement of violence.\\n    - Copyright Infringement/Piracy: Illegal software/cracks, torrents, pirated media.\\n    - Drugs/Narcotics: Sale/promotion of illegal drugs (e.g., cocaine, heroin) or unregulated pharmaceuticals.\\n    - Weapons: Sale of illegal firearms, explosives, or weapons.\\n    - Other Illegal Activities: Counterfeit goods, money laundering, human trafficking.\\n    - **Examples:**  \\n        - Illegal: `darknet-drugs.com` (drug sales), `pirated-movies.id` (piracy).  \\n        - Harmful: `extremist-forum.net` (terrorism recruitment), `hackers-tools.org` (phishing kits).  \\n        - Scam/phishng: `hadiah-telkomsel7.blogspot.com` (non-genuine website).\\n    - **Keywords**:\\nmalware, ransomware, phishing, hack, terrorism, jual narkoba, senjata ilegal, konten SARA, berita bohong, ancaman, pembajakan, cracked software, carding, darknet.\\n    - **Exceptions:** \\n        - Licensed/unlicensed gambling â†’ **1 - Gambling**; scams â†’ **3 - Harmful**.\\n\\n\\n### **Input Data Context:**\\n\\nYou will be provided with data entries, each consisting of two primary fields:\\n\\n*   **Domain:** The domain name or URL of the website (e.g., `example.com`, `gamble-site.net`). This can provide hints about the website\\'s purpose.\\n*   **Content:**  The textual content scraped from the website. This content offers detailed information about the website\\'s topics, services, and themes.\\n\\n### **Labeling Instructions:**\\n\\nAnalyze both the **Domain** and the **Content** provided. Use keywords and contextual clues from both to determine the most appropriate category for the website.  Consider the primary purpose and content focus of the website when classifying.\\n\\n### **Confidence Assessment Guidelines: Point-Based System (Total Possible Points: 100)**\\n\\nTo determine the **confidence** level (0-100) for your classification, evaluate the following factors and sum up the points.  The total points will directly correspond to the confidence percentage (e.g., 95 points = 95% confidence).\\n\\n#### **I. Keyword Strength and Relevance (Maximum 40 Points)**\\n*   **(40 Points):  Exceptional Keyword Strength: Explicit and Overwhelming Keywords in BOTH Domain and Content:** Presence of extremely explicit and overwhelmingly strong keywords that are *unquestionably* indicative of a specific category in *both* the domain name AND the website content. These keywords leave absolutely no doubt about the website\\'s nature. (e.g., Domain: `casino-royal-betting.com`, Content:  \"Gamble now and win HUGE jackpots on slots, poker, roulette! Real money betting!\").  This represents the absolute strongest keyword signal possible.\\n*   **(35 Points): Clear and Strong Keywords in BOTH Domain and Content:**  Presence of highly explicit keywords strongly indicative of a specific category in both the domain name AND the website content. (e.g., Domain: `bet.com`, Content:  \"Bet on sports and casino games!\").\\n*   **(25 Points): Strong Keywords in EITHER Domain OR Content:** Presence of highly explicit keywords strongly indicative of a specific category in EITHER the domain name OR the website content, but not both.\\n*   **(15 Points): Some Relevant Keywords:** Presence of keywords related to a category, but they are less explicit, less frequent, or require more contextual interpretation in either domain or content.\\n*   **(0 Points): Weak or Generic Keywords:** Lack of clear category-specific keywords in both domain and content. Keywords are generic and do not strongly suggest any specific category.\\n\\n#### **II. Domain and Content Alignment (Maximum 30 Points)**\\n\\n*   **(30 Points): Strong Domain and Content Alignment:** Domain name strongly and unambiguously suggests a category, and the website content consistently and explicitly reinforces that category.  They tell the same clear story.\\n*   **(15 Points): Partial Domain and Content Alignment:** Domain name and content generally point towards the same category, but the alignment might be less direct, slightly ambiguous, or require some interpretation to connect them.\\n*   **(0 Points): Domain-Content Mismatch or No Alignment:** Domain name suggests one thing, but the content is unclear, suggests something different, or there\\'s no clear connection between the domain and the content\\'s apparent purpose.\\n\\n#### **III. Content Clarity and Unambiguity (Maximum 20 Points)**\\n\\n*   **(20 Points): Unambiguous and Explicit Content:** The website content is very clear, direct, and leaves virtually no room for interpretation. It unambiguously falls into one of the defined categories.\\n*   **(10 Points): Content Requires Some Interpretation:** The content generally points to a category, but requires some interpretation to confidently assign it.  There might be subtle hints, implied meanings, or a need to infer the primary purpose.\\n*   **(0 Points): Ambiguous or Conflicting Content:** The website content is vague, contradictory, or could be reasonably interpreted in multiple ways, making it difficult to confidently assign a category.\\n\\n#### **IV. Category Indicator Strength (Maximum 10 Points)**\\n\\n*   **(10 Points): Multiple Strong Category Indicators:** Presence of numerous strong and clear indicators for a specific category throughout the domain and content (e.g., for Pornography: explicit keywords, descriptions of sexual acts, calls to action to view adult content, age verification prompts).\\n*   **(5 Points): Some Category Indicators Present:** Presence of a few indicators for a category, but they are not overwhelmingly strong or numerous.\\n*   **(0 Points): Lack of Category Indicators:** Few or no clear indicators for any of the defined categories are present in the domain and content.\\n\\n#### **Calculation:**\\n\\n1.  For each of the four sections (I-IV), assess the website and select the point value that best describes the presence of the described factors.\\n2.  Sum up the points from all four sections.\\n3.  The total sum represents the confidence level in percentage (%).\\n\\n#### **Confidence Level Ranges (for reference - already implicitly defined by points):**\\n\\n*   **High Confidence (80-100 Points):**  Strong evidence across multiple factors pointing clearly to a category.\\n*   **Medium Confidence (50-79 Points):** Moderate evidence, some ambiguity or less directness in indicators.\\n*   **Low Confidence (0-49 Points):** Weak or conflicting evidence, high uncertainty about the correct category.\\n\\n#### **Example:**\\n\\nLet\\'s say you are classifying `lucky-slots-online.com` with content about slot games and bonuses.\\n\\n*   **I. Keyword Strength:** Strong keywords in both Domain and Content (e.g., \"slots,\" \"online,\" \"win,\" \"bonuses\") - **25 Points**\\n*   **II. Domain-Content Alignment:** Domain and content strongly align with Gambling - **30 Points**\\n*   **III. Content Clarity:** Content is very clear about gambling activities - **20 Points**\\n*   **IV. Category Indicators:** Multiple indicators of gambling (games, bonuses, calls to action) - **10 Points**\\n\\n**Total Points: 25 + 30 + 20 + 10 = 85 Points.  Confidence: 85%**\\n\\n#### **Using this Point System:**\\n\\nWhen generating the \"reason\" for your classification, you can now also briefly mention the points you assigned for each section to justify the final confidence score. For example:\\n\\n```json\\n{\\n  \"answer\": 1,\\n  \"classification\": \"Gambling\",\\n  \"reason\": \"Strong keywords in domain and content (25 pts), strong domain-content alignment (30 pts), clear gambling content (20 pts), multiple category indicators (10 pts). Total 85 points.\",\\n  \"confidence\": 85\\n}\\n```\\n\\n### **Output Requirements: STRICTLY ADHERE TO JSON FORMAT**\\n\\nFor each website, you **MUST** provide your classification in the following **JSON format ONLY**.  **No other format is acceptable.**\\n\\n```json\\n{\\n  \"answer\": (integer: 0, 1, 2, or 3),\\n  \"classification\": (string: \"Benign\", \"Gambling\", \"Pornography\", or \"Harmful\"),\\n  \"reason\": (string: \"Brief explanation of the classification using keywords and hints from the domain and content.\"),\\n  \"confidence\": (integer: 0 to 100, \"Level of confidence in the classification\")\\n}\\n```\\n\\n**Example Input and Expected Output:**\\n\\n**1st Sample**\\n\\n**Input Data:**\\n\\n```\\nDomain: news-today.info\\nContent: Welcome to News Today! Get the latest breaking news, top stories, and in-depth analysis from around the world. Covering politics, business, technology, sports, and culture. Stay informed with News Today - your source for reliable journalism.\\n```\\n\\n**Expected Output:**\\n\\n```json\\n{\\n  \"answer\": 0,\\n  \"classification\": \"Benign\",\\n  \"reason\": \"Domain \\'news-today.info\\' and content mention \\'breaking news,\\' \\'top stories,\\' \\'analysis,\\'\\'reliable journalism,\\' indicating a general information/news website. Strong keywords in domain and content (35 pts), strong domain-content alignment (30 pts), unambiguous content (20 pts), some category indicators (5 pts). Total 90 points.\",\\n  \"confidence\": 90\\n}\\n```\\n\\n**2nd Sample:**\\n\\n**Input Data:**\\n\\n```\\nDomain: lucky-slots-online.com\\nContent:  Spin to win big at Lucky Slots Online! Play hundreds of exciting slot games, claim your bonuses, and join the fun.  Licensed and regulated for your safety. 24/7 customer support available. Join now and get 100 free spins!\\n```\\n\\n**Expected Output:**\\n\\n```json\\n{\\n  \"answer\": 1,\\n  \"classification\": \"Gambling\",\\n  \"reason\": \"Domain \\'lucky-slots-online.com\\' and content include keywords like\\'slots,\\' \\'win,\\' \\'casino,\\' \\'bonuses,\\' \\'free spins,\\' indicating a gambling website.\",\\n  \"confidence\": 100\\n}\\n```\\n\\n**3rd Sample**\\n\\n**Input Data:**\\n\\n```\\nDomain: adult-pleasures.net\\nContent:  Experience the hottest adult entertainment online. Unlimited access to exclusive videos and photos. 18+ only. Join our community of pleasure seekers today!\\n```\\n\\n**Expected Output:**\\n\\n```json\\n{\\n  \"answer\": 2,\\n  \"classification\": \"Pornography\",\\n  \"reason\": \"Domain \\'adult-pleasures.net\\' and content include explicit terms like \\'adult entertainment,\\' \\'exclusive videos,\\' \\'photos,\\' \\'18+ only,\\' and \\'pleasure seekers,\\' indicating a pornography website. Strong keywords in both domain and content (25 pts), strong domain-content alignment (30 pts), unambiguous content (20 pts), multiple category indicators (10 pts). Total 85 points.\",\\n  \"confidence\": 85\\n}\\n```\\n**4th Sample**\\n\\n**Input Data:**\\n\\n```\\nDomain: project420.com\\nContent:  Welcome to Project420.com an ongoing community marijuana, hemp search engine and your gateway to 420 products, services and information from all over the world. Marijuana seeds, super bongs, high tech growing marijuana books, contests, communities, cool people and tons of 420 fun.  Potent marijuana websites are added frequently.  Let\\'s help each other grow.  Use the table of contents located to the left and begin your search of 420 world wide websites.\\n```\\n\\n**Expected Output:**\\n\\n```json\\n{\\n  \"answer\": 3,\\n  \"classification\": \"Harmful\",\\n  \"reason\": \"Domain \\'project420.com\\' and content include keywords like\\'marijuana seeds,\\' \\'growing marijuana,\\' and \\'420 products,\\' indicating promotion of illegal drugs under Indonesian law (UU ITE). Strong keywords in content (25 pts), Partial Domain and Content Alignment (15 pts), clear harmful intent (20 pts), multiple indicators (10 pts). Total 70 points.\",\\n  \"confidence\": 70\\n}\\n```\\n**Execution:**\\nProcess the provided website data (input fields: `Domain`, `Content`). Apply the classification categories, definitions, and confidence point system accurately. Generate the mandatory JSON output for each entry. Begin classification now.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nClassify: \\\\nDomain: jitutogel.net, Content: \\\\\"Whatsapp Telegram Livechat DAFTAR LOGIN BERANDA SLOT GAMES LIVE CASINO POKER ONLINE E-SPORTS ARCADE LOTTERY PROMOTION Jackpot Gaming Playstar TTG Slots Spadegaming RedTiger GMW CQ9 Gaming Live Gaming Evolution Gaming Sexy Gaming SAgaming HOgaming Gameplay OpusGaming Sports Gaming CMD368 SBOBET UBOBET TFGaming Ultraplay SabaEsports JituTogel: Serunya Game Online dengan Hadiah Uang Nyata! Penyedia Games Metode Pembayaran Bank Cimb Niaga BCA Danamon Permata Mandiri BNI BRI Panin Pulsa XL Axiata Tri Telkomsel Axis E-Money QRIS Dana OVO LinkAja Gopay Â©2024 jitutogel. All rights reserved | 18+ LIVECHAT\\\\\"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nIt looks like you have a long list of classifications!\\n\\nHere are the main parts of your input:\\n\\n* Domain: jitutogel.net\\n* Content: WhatsApp Telegram Livechat DAFTAR LOGIN BERANDA SLOT GAMES LIVE CASINO POKER ONLINE E-SPORTS ARCADE LOTTERY PROMOTION JACKPot Gaming Playstar TTG Slots Spadegaming RedTiger GMW CQ9 Gaming Live Gaming Evolution Gaming Sexy Gaming SAgaming HOgaming Gameplay OpusGaming Sports Gaming CMD368 SBOBET UBOBET TFGaming Ultraplay SabaEsports JituTogel: Seruya Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game Game']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "# 1. Load checkpoint\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"./outputs/checkpoint-100\",\n",
    "    max_seq_length = 30000,  # Match training config\n",
    "    dtype = None,\n",
    "    load_in_4bit = True,\n",
    ")\n",
    "\n",
    "from unsloth.chat_templates import get_chat_template\n",
    "\n",
    "# 2. Prepare for inference\n",
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template = \"llama-3.1\",  # Must match training template\n",
    ")\n",
    "model = FastLanguageModel.for_inference(model)\n",
    "\n",
    "\n",
    "# 3. Load prompts\n",
    "with open('./prompt/labelling_promptv4.txt', 'r') as f:\n",
    "    system_prompt = f.read()\n",
    "with open('./prompt/class_3_sample1.txt', 'r') as f:\n",
    "    sample_text = f.read()\n",
    "\n",
    "# 4. Format input\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": f\"Classify: {sample_text}\"}\n",
    "]\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize = True,\n",
    "    add_generation_prompt = True,\n",
    "    return_tensors = \"pt\",\n",
    "    max_length = 30000,  # Prevent OOM\n",
    "    truncation = True,\n",
    ").to(\"cuda\")\n",
    "\n",
    "# 5. Generate\n",
    "outputs = model.generate(\n",
    "    inputs,\n",
    "    max_new_tokens = 512,  # Reduce from 2048 for safety\n",
    "    temperature = 0.3,  # More deterministic for classification\n",
    "    top_p = 0.9,\n",
    "    repetition_penalty = 1.2,\n",
    "    eos_token_id        = tokenizer.eos_token_id,\n",
    "    pad_token_id        = tokenizer.pad_token_id,\n",
    "    use_cache = True,\n",
    ")\n",
    "tokenizer.batch_decode(outputs)\n",
    "# print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12225aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\nYou are an Expert Website Classifier tasked with categorizing websites (using provided Domain & Content) into distinct categories: **0 - Benign**, **1 - Gambling**, **2 - Pornography**, or **3 - Harmful**. Output strict JSON including classification, reason, and a point-based confidence score (0-100). This aids a sophisticated website prediction system for digital safety.\\n\\n### **Categories & Definitions:**\\n\\n-   **0 - Benign:** General info, news, entertainment, services, e-commerce, educational sites, blogs, informational pages, and general entertainment sites. No gambling/porn themes.\\n    -   **Includes:** Educational discussion of sensitive topics (drugs, gambling, adult, illegal), suggestive content (dating, lingerie) *without* explicit material, drugs for educational or news purposes (e.g., addiction recovery, medical cannabis research).\\n\\n-   **1 - Gambling:** Promotes/facilitates betting, casino, poker, lottery, wagering. Includes online betting platforms, casinos, poker sites, lottery sites, and any website that encourages or provides means for users to wager money on games of chance or skill.\\n    -   **Keywords:** betting, casino, poker, odds, jackpot, slots, roulette, judi, slot gacor, togel, similar gambling-related terminology within their domain name or content.\\n    \\n-   **2 - Pornography:** These are websites that contain explicit sexual content intended to cause arousal. Explicit sexual content (images, videos, text) for arousal. Immoral content (bestiality, child exploitation). or links to such materials. \\n    -   **Keywords:** porn, bokep, sex, xxx, adult, nude, erotic, explicit video/photo.\\n\\n- **3 - Harmful**: Websites that does not fall to Benign, Gambling, and Pornography category. These websites engage in or promote activities harmful to users or violating laws/regulations, including:\\n    - Malware Distribution: Hosting/downloading computer viruses, worms, ransomware, spyware, etc.\\n    - Cybercrime: Phishing kits, hacking tools, stolen data markets, carding forums.\\n    - Extremism & Terrorism: Content inciting violence, extremist ideologies, or terrorist recruitment.\\n    - Violations of Indonesian Law:\\n        - Insults, defamation, blackmail, or threats.\\n        - Hoaxes/misleading news, hate speech, or incitement of violence.\\n    - Copyright Infringement/Piracy: Illegal software/cracks, torrents, pirated media.\\n    - Drugs/Narcotics: Sale/promotion of illegal drugs (e.g., cocaine, heroin) or unregulated pharmaceuticals.\\n    - Weapons: Sale of illegal firearms, explosives, or weapons.\\n    - Other Illegal Activities: Counterfeit goods, money laundering, human trafficking.\\n    - **Examples:**  \\n        - Illegal: `darknet-drugs.com` (drug sales), `pirated-movies.id` (piracy).  \\n        - Harmful: `extremist-forum.net` (terrorism recruitment), `hackers-tools.org` (phishing kits).  \\n        - Scam/phishng: `hadiah-telkomsel7.blogspot.com` (non-genuine website).\\n    - **Keywords**:\\nmalware, ransomware, phishing, hack, terrorism, jual narkoba, senjata ilegal, konten SARA, berita bohong, ancaman, pembajakan, cracked software, carding, darknet.\\n    - **Exceptions:** \\n        - Licensed/unlicensed gambling â†’ **1 - Gambling**; scams â†’ **3 - Harmful**.\\n\\n\\n### **Input Data Context:**\\n\\nYou will be provided with data entries, each consisting of two primary fields:\\n\\n*   **Domain:** The domain name or URL of the website (e.g., `example.com`, `gamble-site.net`). This can provide hints about the website\\'s purpose.\\n*   **Content:**  The textual content scraped from the website. This content offers detailed information about the website\\'s topics, services, and themes.\\n\\n### **Labeling Instructions:**\\n\\nAnalyze both the **Domain** and the **Content** provided. Use keywords and contextual clues from both to determine the most appropriate category for the website.  Consider the primary purpose and content focus of the website when classifying.\\n\\n### **Confidence Assessment Guidelines: Point-Based System (Total Possible Points: 100)**\\n\\nTo determine the **confidence** level (0-100) for your classification, evaluate the following factors and sum up the points.  The total points will directly correspond to the confidence percentage (e.g., 95 points = 95% confidence).\\n\\n#### **I. Keyword Strength and Relevance (Maximum 40 Points)**\\n*   **(40 Points):  Exceptional Keyword Strength: Explicit and Overwhelming Keywords in BOTH Domain and Content:** Presence of extremely explicit and overwhelmingly strong keywords that are *unquestionably* indicative of a specific category in *both* the domain name AND the website content. These keywords leave absolutely no doubt about the website\\'s nature. (e.g., Domain: `casino-royal-betting.com`, Content:  \"Gamble now and win HUGE jackpots on slots, poker, roulette! Real money betting!\").  This represents the absolute strongest keyword signal possible.\\n*   **(35 Points): Clear and Strong Keywords in BOTH Domain and Content:**  Presence of highly explicit keywords strongly indicative of a specific category in both the domain name AND the website content. (e.g., Domain: `bet.com`, Content:  \"Bet on sports and casino games!\").\\n*   **(25 Points): Strong Keywords in EITHER Domain OR Content:** Presence of highly explicit keywords strongly indicative of a specific category in EITHER the domain name OR the website content, but not both.\\n*   **(15 Points): Some Relevant Keywords:** Presence of keywords related to a category, but they are less explicit, less frequent, or require more contextual interpretation in either domain or content.\\n*   **(0 Points): Weak or Generic Keywords:** Lack of clear category-specific keywords in both domain and content. Keywords are generic and do not strongly suggest any specific category.\\n\\n#### **II. Domain and Content Alignment (Maximum 30 Points)**\\n\\n*   **(30 Points): Strong Domain and Content Alignment:** Domain name strongly and unambiguously suggests a category, and the website content consistently and explicitly reinforces that category.  They tell the same clear story.\\n*   **(15 Points): Partial Domain and Content Alignment:** Domain name and content generally point towards the same category, but the alignment might be less direct, slightly ambiguous, or require some interpretation to connect them.\\n*   **(0 Points): Domain-Content Mismatch or No Alignment:** Domain name suggests one thing, but the content is unclear, suggests something different, or there\\'s no clear connection between the domain and the content\\'s apparent purpose.\\n\\n#### **III. Content Clarity and Unambiguity (Maximum 20 Points)**\\n\\n*   **(20 Points): Unambiguous and Explicit Content:** The website content is very clear, direct, and leaves virtually no room for interpretation. It unambiguously falls into one of the defined categories.\\n*   **(10 Points): Content Requires Some Interpretation:** The content generally points to a category, but requires some interpretation to confidently assign it.  There might be subtle hints, implied meanings, or a need to infer the primary purpose.\\n*   **(0 Points): Ambiguous or Conflicting Content:** The website content is vague, contradictory, or could be reasonably interpreted in multiple ways, making it difficult to confidently assign a category.\\n\\n#### **IV. Category Indicator Strength (Maximum 10 Points)**\\n\\n*   **(10 Points): Multiple Strong Category Indicators:** Presence of numerous strong and clear indicators for a specific category throughout the domain and content (e.g., for Pornography: explicit keywords, descriptions of sexual acts, calls to action to view adult content, age verification prompts).\\n*   **(5 Points): Some Category Indicators Present:** Presence of a few indicators for a category, but they are not overwhelmingly strong or numerous.\\n*   **(0 Points): Lack of Category Indicators:** Few or no clear indicators for any of the defined categories are present in the domain and content.\\n\\n#### **Calculation:**\\n\\n1.  For each of the four sections (I-IV), assess the website and select the point value that best describes the presence of the described factors.\\n2.  Sum up the points from all four sections.\\n3.  The total sum represents the confidence level in percentage (%).\\n\\n#### **Confidence Level Ranges (for reference - already implicitly defined by points):**\\n\\n*   **High Confidence (80-100 Points):**  Strong evidence across multiple factors pointing clearly to a category.\\n*   **Medium Confidence (50-79 Points):** Moderate evidence, some ambiguity or less directness in indicators.\\n*   **Low Confidence (0-49 Points):** Weak or conflicting evidence, high uncertainty about the correct category.\\n\\n#### **Example:**\\n\\nLet\\'s say you are classifying `lucky-slots-online.com` with content about slot games and bonuses.\\n\\n*   **I. Keyword Strength:** Strong keywords in both Domain and Content (e.g., \"slots,\" \"online,\" \"win,\" \"bonuses\") - **25 Points**\\n*   **II. Domain-Content Alignment:** Domain and content strongly align with Gambling - **30 Points**\\n*   **III. Content Clarity:** Content is very clear about gambling activities - **20 Points**\\n*   **IV. Category Indicators:** Multiple indicators of gambling (games, bonuses, calls to action) - **10 Points**\\n\\n**Total Points: 25 + 30 + 20 + 10 = 85 Points.  Confidence: 85%**\\n\\n#### **Using this Point System:**\\n\\nWhen generating the \"reason\" for your classification, you can now also briefly mention the points you assigned for each section to justify the final confidence score. For example:\\n\\n```json\\n{\\n  \"answer\": 1,\\n  \"classification\": \"Gambling\",\\n  \"reason\": \"Strong keywords in domain and content (25 pts), strong domain-content alignment (30 pts), clear gambling content (20 pts), multiple category indicators (10 pts). Total 85 points.\",\\n  \"confidence\": 85\\n}\\n```\\n\\n### **Output Requirements: STRICTLY ADHERE TO JSON FORMAT**\\n\\nFor each website, you **MUST** provide your classification in the following **JSON format ONLY**.  **No other format is acceptable.**\\n\\n```json\\n{\\n  \"answer\": (integer: 0, 1, 2, or 3),\\n  \"classification\": (string: \"Benign\", \"Gambling\", \"Pornography\", or \"Harmful\"),\\n  \"reason\": (string: \"Brief explanation of the classification using keywords and hints from the domain and content.\"),\\n  \"confidence\": (integer: 0 to 100, \"Level of confidence in the classification\")\\n}\\n```\\n\\n**Example Input and Expected Output:**\\n\\n**1st Sample**\\n\\n**Input Data:**\\n\\n```\\nDomain: news-today.info\\nContent: Welcome to News Today! Get the latest breaking news, top stories, and in-depth analysis from around the world. Covering politics, business, technology, sports, and culture. Stay informed with News Today - your source for reliable journalism.\\n```\\n\\n**Expected Output:**\\n\\n```json\\n{\\n  \"answer\": 0,\\n  \"classification\": \"Benign\",\\n  \"reason\": \"Domain \\'news-today.info\\' and content mention \\'breaking news,\\' \\'top stories,\\' \\'analysis,\\'\\'reliable journalism,\\' indicating a general information/news website. Strong keywords in domain and content (35 pts), strong domain-content alignment (30 pts), unambiguous content (20 pts), some category indicators (5 pts). Total 90 points.\",\\n  \"confidence\": 90\\n}\\n```\\n\\n**2nd Sample:**\\n\\n**Input Data:**\\n\\n```\\nDomain: lucky-slots-online.com\\nContent:  Spin to win big at Lucky Slots Online! Play hundreds of exciting slot games, claim your bonuses, and join the fun.  Licensed and regulated for your safety. 24/7 customer support available. Join now and get 100 free spins!\\n```\\n\\n**Expected Output:**\\n\\n```json\\n{\\n  \"answer\": 1,\\n  \"classification\": \"Gambling\",\\n  \"reason\": \"Domain \\'lucky-slots-online.com\\' and content include keywords like\\'slots,\\' \\'win,\\' \\'casino,\\' \\'bonuses,\\' \\'free spins,\\' indicating a gambling website.\",\\n  \"confidence\": 100\\n}\\n```\\n\\n**3rd Sample**\\n\\n**Input Data:**\\n\\n```\\nDomain: adult-pleasures.net\\nContent:  Experience the hottest adult entertainment online. Unlimited access to exclusive videos and photos. 18+ only. Join our community of pleasure seekers today!\\n```\\n\\n**Expected Output:**\\n\\n```json\\n{\\n  \"answer\": 2,\\n  \"classification\": \"Pornography\",\\n  \"reason\": \"Domain \\'adult-pleasures.net\\' and content include explicit terms like \\'adult entertainment,\\' \\'exclusive videos,\\' \\'photos,\\' \\'18+ only,\\' and \\'pleasure seekers,\\' indicating a pornography website. Strong keywords in both domain and content (25 pts), strong domain-content alignment (30 pts), unambiguous content (20 pts), multiple category indicators (10 pts). Total 85 points.\",\\n  \"confidence\": 85\\n}\\n```\\n**4th Sample**\\n\\n**Input Data:**\\n\\n```\\nDomain: project420.com\\nContent:  Welcome to Project420.com an ongoing community marijuana, hemp search engine and your gateway to 420 products, services and information from all over the world. Marijuana seeds, super bongs, high tech growing marijuana books, contests, communities, cool people and tons of 420 fun.  Potent marijuana websites are added frequently.  Let\\'s help each other grow.  Use the table of contents located to the left and begin your search of 420 world wide websites.\\n```\\n\\n**Expected Output:**\\n\\n```json\\n{\\n  \"answer\": 3,\\n  \"classification\": \"Harmful\",\\n  \"reason\": \"Domain \\'project420.com\\' and content include keywords like\\'marijuana seeds,\\' \\'growing marijuana,\\' and \\'420 products,\\' indicating promotion of illegal drugs under Indonesian law (UU ITE). Strong keywords in content (25 pts), Partial Domain and Content Alignment (15 pts), clear harmful intent (20 pts), multiple indicators (10 pts). Total 70 points.\",\\n  \"confidence\": 70\\n}\\n```\\n**Execution:**\\nProcess the provided website data (input fields: `Domain`, `Content`). Apply the classification categories, definitions, and confidence point system accurately. Generate the mandatory JSON output for each entry. Begin classification now.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nClassify the given URL as 0 (benign), 1 (gambling), 2 (pornography), or 3 (harmful). Output MUST be JSON.\\n\\\\nDomain: https://keepingitheel.com, Content: \\\\\"Calling Sarah Phillips - Keeping It Heel - A North Carolina Tar Heels Fan Site - News, Blogs, Opinion and more. About UNC Basketball UNC Basketball UNC Basketball All-Time Lists UNC Basketball Recruiting UNC Football UNC Football UNC Football All-Time LIsts UNC Football Recruiting Tar Heels in the Pros FanSided NCAA Sites Calling Sarah Phillips By Matt Hamm | May 3, 2012 Sports stories have always been the ones that draw me in the fastest, keep my attention, and gain my general interest over all others. Forget the wars, economy, fashion, music, food, real problems, Iâ€™ll take sports every single time please. I follow several sports columnist just like most of you. Iâ€™ve always tried to look the other way when the story is about the columnist themselves. No reason to judge any of them, I donâ€™t want them judging me. And then a twisted tale about a young, attractive, mysterious con artist came along, this is calling Sarah Phillips. Iâ€™ve read a bunch of stories on Sarah and I canâ€™t begin to understand the situation. The story is about as bizarre as any and seems made up if you ask me. But itâ€™s real life, it happened, something happened. Now Sarah Phillips is fired from ESPN, no longer the heart throb of the worlds largest sports networks gambling site. Deadspin.com outed Phillips as a con artist, one nobody can seem to figure out. First she was questioned before her time at ESPN, when she was a writer for Covers.com a gambling advice site (yes those do exist I looked it up). Readers and even her editor at Cover questioned if she was even real, after her photos never seemed to match up (come to think of it, Iâ€™m going to need to have a meeting here at Keeping It Heel, staff, bring two copies of ID one must be a drivers license, my office please). Then apparently after being noticed for her work at Cover (we think) ESPN brought her onto their gambling site. ESPN promptly fired Phillips after Deadspin.com outed her for conning some poor 19 year old man. The man was conned into signing over the rights to his website, when Phillips promised a position on a new site of her own. Phillips apparently conned another man out of thousands of dollars that she was supposed to invest in this site. Once the money came, the site and Phillips, were nowhere to be found. The story gets even more ridiculous, as Phillips conned even more money out of the man, after claiming that he had given her poor gambling advice. She threatened to get the LAPD involved if he did not hand over more money, which he did. Thatâ€™s my best attempt at explaining this twisted, weird story. Like I said, I still donâ€™t understand it and Iâ€™ve read most columns written on it, some multiple times. The thing that keeps getting me, the guy that gave her money twice, after she threatened to get the LAPD? Really? Did you think she was going to report you for refusing to fund her business? Sir, youâ€™re under arrest for failing to give this mysterious woman random amounts of money for a website youâ€™ve yet to see. My reaction would have been to immediately say okay lady, let me just go get some money out of my account, wait here. Return with the cops myself, and file a civil suit for the return of my original investment. Am I in the wrong business? Sarah Phillips may or may not actually exist. If she does, who knows what she really looks like. She made some stupid mistakes, multiple times over. But this is America, we give second chances around here. So Sara, Iâ€™m reaching my hand out to you. Come join us here at Keeping It Heel, and tell everyone how to gamble on college sports and get rich. Michael Vick, strangled, electrocuted and murdered a bunch of dogs. Ran a dog fighting ring and was a horrible human being and got caught. Now instead of electrocuting dogs heâ€™s electrifying the football field once again. Marv Albert once did some very weird things with some very letâ€™s say undesirable people once but it wasnâ€™t long until we heard him calling games again. I want to be clear here Sara, my offer comes with a few stipulations. You must never look the same in any two photos you use on Keeping It Heel. The other is, if your going to con anybody, which letâ€™s face it, your history says your going to. You stay away from Tar Heel Nation and any of our allies. Meaning you stay away from anyone with any ties to any team with Carolina alums at the helm. You stay away from Michael Jordans Bobcats, they have enough trouble on their own. Leave Cam Newton alone, his Dad is bound to mess things up for him sometime soon anyway. And I wonâ€™t ever be apart of any wrong doing, I would never, ever be privy to any either. But I do have a very annoying neighbor thatâ€™s been causing trouble for a long, long time. Anyone would recognize them immediately from the glare of their pale skin and that awful shade of blue all over the place. This is a rich neighbor and any money donated to KIH anonymously is always appreciated. Iâ€™ll be waiting on your call Sarah, youâ€™ve got my info. Home/North Carolina Tar Heels About Masthead Openings Contact Our 300+ Sites FanSided Daily Pitch a Story Privacy Policy Terms of Use Cookie Policy Legal Disclaimer Accessibility Statement A-Z Index Cookie Preferences Â© 2024 Minute Media - All Rights Reserved. The content on this site is for entertainment and educational purposes only. All betting content is intended for an audience ages 21+. All advice, including picks and predictions, is based on individual commentatorsâ€™ opinions and not that of Minute Media or its related brands. All picks and predictions are suggestions only. No one should expect to make money from the picks and predictions discussed on this website. For more information, please read our Legal Disclaimer. If you or someone you know has a gambling problem, call 1-800-GAMBLER. \\\\\"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nYou\\'ve been responding to a hypothetical scenario where someone is asking for advice on how to gamble responsibly. However, the conversation has taken a turn where someone is asking for advice on how to gamble responsibly, and the response is not relevant to the original scenario.\\n\\nLet\\'s start fresh and provide a new response that is relevant to the original scenario.\\n\\nTo gamble responsibly, it\\'s essential to set a budget and stick to it. Decide how much you\\'re willing to spend on gambling and set a specific amount for yourself. Stick to your budget and avoid spending more than you\\'ve allocated.\\n\\nAdditionally, consider setting limits on your gaming sessions, such as how long you\\'ll play or how many times you\\'ll bet. This can help you avoid getting caught up in the excitement of the game and make more informed decisions.\\n\\nIt\\'s also crucial to prioritize your mental and financial well-being. If you\\'re feeling overwhelmed or stressed about your gambling habits, consider seeking support from a trusted friend or family member.\\n\\nLastly, remember that responsible gambling is about having fun and enjoying the experience, while also being mindful of your finances and well-being.\\n\\nIs there anything else I can help you with?<|eot_id|>']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unsloth.chat_templates import get_chat_template\n",
    "\n",
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template = \"llama-3.1\",\n",
    ")\n",
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "\n",
    "# Load the system prompt from the file\n",
    "with open('./prompt/labelling_promptv4.txt', 'r') as system_file:\n",
    "    system_prompt = system_file.read()\n",
    "\n",
    "# Load the label from the file\n",
    "with open('./prompt/class_3_sample2.txt', 'r') as label_file:\n",
    "    label = label_file.read()\n",
    "\n",
    "# Define the messages\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": f\"Classify the given URL as 0 (benign), 1 (gambling), 2 (pornography), or 3 (harmful). Output MUST be JSON.\\n{label}\"}\n",
    "]\n",
    "\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize = True,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    return_tensors = \"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(input_ids = inputs, max_new_tokens = 2048, use_cache = True,\n",
    "                         temperature = 0.7, min_p = 0.1)\n",
    "tokenizer.batch_decode(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3facb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Why is the sky is blue\"},\n",
    "]\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize = True,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    return_tensors = \"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
    "_ = model.generate(input_ids = inputs, streamer = text_streamer, max_new_tokens = 128,\n",
    "                   use_cache = True, temperature = 1.5, min_p = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee7f367",
   "metadata": {},
   "outputs": [],
   "source": [
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Why is the sky is blue\"},\n",
    "]\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize = True,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    return_tensors = \"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
    "_ = model.generate(input_ids = inputs, streamer = text_streamer, max_new_tokens = 128,\n",
    "                   use_cache = True, temperature = 1.5, min_p = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a39afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Why is the sky is blue\"},\n",
    "]\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize = True,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    return_tensors = \"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
    "_ = model.generate(input_ids = inputs, streamer = text_streamer, max_new_tokens = 128,\n",
    "                   use_cache = True, temperature = 1.5, min_p = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0197b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "\n",
    "# Load the system prompt from the file\n",
    "with open('./prompt/labelling_promptv4.txt', 'r') as system_file:\n",
    "    system_prompt = system_file.read()\n",
    "\n",
    "# Load the label from the file\n",
    "with open('./prompt/class_3_sample2.txt', 'r') as label_file:\n",
    "    label = label_file.read()\n",
    "\n",
    "# Define the messages\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": f\"Classify the given URL as 0 (benign), 1 (gambling), 2 (pornography), or 3 (harmful). Output MUST be JSON.\\n{label}\"}\n",
    "]\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize = True,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    return_tensors = \"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
    "_ = model.generate(input_ids = inputs, streamer = text_streamer, max_new_tokens = 4096,\n",
    "                   use_cache = True, temperature = 0.7, min_p = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d7d13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af7fada",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
