{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10039837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473b0932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sharegpt(system, input_suffix, dataset):\n",
    "    \"\"\"\n",
    "    Convert website classification dataset to ShareGPT format while preserving original Unicode characters.\n",
    "    \n",
    "    Args:\n",
    "        system (str): System prompt\n",
    "        input_suffix (str): Suffix to append to the human message\n",
    "        dataset (pd.DataFrame): Input DataFrame with columns:\n",
    "            ['Domain', 'Content', 'Label', 'classification', 'reason', 'confidence']\n",
    "            \n",
    "    Returns:\n",
    "        list: List of conversations in ShareGPT format with preserved Unicode\n",
    "    \"\"\"\n",
    "    sharegpt_data = []\n",
    "    \n",
    "    for _, row in dataset.iterrows():\n",
    "        # Construct human message with proper Unicode handling\n",
    "        domain = row['Domain']\n",
    "        content = row['Content']\n",
    "        \n",
    "        # Build human message with direct Unicode inclusion\n",
    "        human_value = (\n",
    "            f\"{input_suffix}\\n\"\n",
    "            f\"Domain: {domain}, \"\n",
    "            f'Content: \"{content}\"'  # Direct string interpolation with quotes\n",
    "        )\n",
    "        \n",
    "        # Construct GPT response with Unicode preservation\n",
    "        gpt_response = {\n",
    "            \"answer\": int(row['Label']),\n",
    "            \"classification\": row['classification'],\n",
    "            \"reason\": row['reason'],\n",
    "            \"confidence\": int(row['confidence'])\n",
    "        }\n",
    "        \n",
    "        # Create conversation entry with ensure_ascii=False\n",
    "        conversation = [\n",
    "            {\"from\": \"system\", \"value\": system},\n",
    "            {\"from\": \"human\", \"value\": human_value},\n",
    "            {\"from\": \"gpt\", \"value\": json.dumps(gpt_response, ensure_ascii=False)}\n",
    "        ]\n",
    "        \n",
    "        sharegpt_data.append(conversation)\n",
    "    \n",
    "    return sharegpt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca07748d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./dataset/harmful.csv')\n",
    "with open('system_prompt.txt', 'r', encoding='utf-8') as f:\n",
    "    system_prompt = f.read()\n",
    "\n",
    "# Convert to ShareGPT format with Unicode preservation\n",
    "formatted_data = to_sharegpt(\n",
    "    system=\"You are an expert multilingual website classifier\",\n",
    "    input_suffix=\"Classify the given URL as 0 (benign), 1 (gambling), 2 (pornography), or 3 (harmful). Output MUST be JSON.\\n\",\n",
    "    dataset=df\n",
    ")\n",
    "\n",
    "# Save with UTF-8 encoding and Unicode preservation\n",
    "with open('multilingual_sharegpt.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(formatted_data, f, ensure_ascii=False, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-wsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
